<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Hadoop | Jetoile]]></title>
  <link href="http://blog.jetoile.fr/blog/categories/hadoop/atom.xml" rel="self"/>
  <link href="http://blog.jetoile.fr/"/>
  <updated>2016-01-19T19:44:55+01:00</updated>
  <id>http://blog.jetoile.fr/</id>
  <author>
    <name><![CDATA[Khanh Maudoux]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hadoop ecosysteme bootstrap]]></title>
    <link href="http://blog.jetoile.fr/2016/01/hadoop-ecosysteme-bootstrap.html"/>
    <updated>2016-01-18T10:00:00+01:00</updated>
    <id>http://blog.jetoile.fr/2016/01/hadoop-ecosysteme-bootstrap</id>
    <content type="html"><![CDATA[<p><img src="/images/hadoop-all.png" alt="left-small" />
Comme je l'ai déjà dit dans un article <a href="/2015/10/hadoop-et-son-ecosysteme.html">précédent</a>, la force d'Hadoop n'est plus dans Hadoop en lui-même mais plutôt dans son écosystème.</p>

<p>Du coup, même lorsqu'on développe avec Spark, il est courant de vouloir s'interfacer avec le métastore de Hive ou encore avec SolR si l'objectif est de vouloir indexer dans ce dernier.</p>

<p>Parfois encore, l'objectif est de lire ou d'écrire de Kafka via Spark (ou en Spark Streaming).</p>

<p>Ainsi, lorsqu'on fait du développement avec des composants &ldquo;BigData&rdquo;, on a souvent besoin d'un écosystème complet.</p>

<p>Alors, bien sûr, dans un monde idéal, il est possible de disposer de tout l'écosystème via Docker ou via une machine virtuelle. Pourtant, parfois, il n'est pas possible de disposer de la pleine puissance de son poste parce qu'on est, parfois (sic&hellip;), dans un contexte où disposer des droits administrateurs de son poste (et pire quand il s'agit d'un poste sous Windows&hellip;) est impossible.</p>

<p>Pour ce faire, il existe quelques solutions comme <a href="https://github.com/sakserv/hadoop-mini-clusters">Hadoop-mini-clusters</a>. Cependant, chaque composant doit alors être démarré dans le bon ordre et il faut avouer que c'est un peu verbeux&hellip;</p>

<p>En outre, les couches clientes fonctionnent principalement dans la même JVM.</p>

<p>L'objectif de ce post est de proposer une alternative beaucoup moins verbeuse et plus pratique.</p>

<p>Il ne s'agit que d'une simple surcouche à Hadoop-mini-clusters mais la solution proposée offre également d'autres possibilités qui ne sont pas offertes par la solution :</p>

<ul>
<li>possibilité de disposer d'un SolR qu'il soit en mode embedded ou en mode cloud</li>
<li>possibilité d'avoir un oozie accessible par un client externe à la JVM</li>
</ul>


<p>De plus, la solution proposée dans cet article (enfin plutôt sur mon <a href="https://github.com/jetoile/hadoop-bootstrap">github</a>&hellip;) propose :</p>

<ul>
<li>de démarrer l'écosystème nécessaire dans un contexte de Test d'intégration</li>
<li>de démarrer l'écosystème nécessaire en mode standalone avec une simple commande</li>
</ul>


<!-- more -->


<h1>Contexte et proposition</h1>

<p>Comme je l'ai dit précédemment, le besoin était de pouvoir disposer de l'écosystème nécessaire à l'exécution de tests d'intégration mais également de pouvoir démarrer l'écosystème nécessaire en mode <em>standalone</em>.</p>

<p>Bien sûr, le tout capable de fonctionner sous Linux mais aussi sous Windows&hellip; (<em>ndlr</em> : oui&hellip; on n'a pas toujours la main sur ce que nous impose le client&hellip; :&lsquo;( )</p>

<p><a href="https://github.com/sakserv/hadoop-mini-clusters">Hadoop-mini-clusters</a> est un composant très pratique mais un peu verbeux. En outre, devoir configurer chacun des composants alors que, souvent, une configuration par défaut est largement suffisante me semblait un peu inutile.</p>

<p>Enfin, comme je l'ai déjà dit, <a href="https://github.com/sakserv/hadoop-mini-clusters">Hadoop-mini-clusters</a> a été conçu pour les TU/TI mais dans un cas de foncionnement en mode <em>standalone</em> il faut alors accéder aux composants de manière <em>remote</em>.</p>

<p>Parmi les besoins, les composants suivants :</p>

<ul>
<li>HDFS</li>
<li>Zookeeper</li>
<li>HBase</li>
<li>Hive (ie. HiveMetastore et Hiveserver2)</li>
<li>Kafka</li>
<li>Oozie</li>
<li>SolRCloud</li>
<li>SolR en mode <em>embedded</em></li>
</ul>


<p>Concernant les parties Spark ou MapReduce, ces frameworks disposant déjà d'un mode &ldquo;développement&rdquo;, il m'était inutile de les proposer dans ma solution.</p>

<p>La surcouche proposée (que j'ai décidé d'appeler <strong>Hadoop-bootstrap</strong>) se trouve <a href="https://github.com/jetoile/hadoop-bootstrap">ici</a></p>

<p>Elle nécessite cependant quelques pré-requis&hellip;</p>

<h1>Prérequis</h1>

<p>Pour fonctionner, Hadoop-bootstrap nécessite d'avoir téléchargé et décompressé Hadoop sur son poste. Dans mon cas, j'ai juste récupéré la version d'<a href="http://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.7.1/hadoop-2.7.1.tar.gz">Apache</a> que j'ai décompressée dans <code>/opt/hadoop</code></p>

<p>Il faut ensuite positionner la variable d'environnement <code>HADOOP_HOME</code> à l'endroit où la version d'Hadoop a été décompressée.</p>

<p>Pour l'utilisation de Oozie, il est nécessaire de télécharger les <code>sharelib</code> de Oozie qui contient les librairies permettant de lancer des actions Hive, Spark, Shell ou autre : <a href="http://s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.3.2.0/tars/oozie-4.2.0.2.3.2.0-2950-distro.tar.gz">http://s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.3.2.0/tars/oozie-4.2.0.2.3.2.0-2950-distro.tar.gz</a></p>

<p>Il suffit alors de modifier le fichier <code>default.properties</code> en y renseignant les variables <code>HADOOP_HOME</code> et <code>oozie.sharelib.path</code> avec les bonnes valeurs.</p>

<h1>Fonctionnement</h1>

<p>Une fois la partie prérequis réalisée, il ne reste plus qu'à générer :</p>

<ul>
<li>le jar si le besoin est d'utiliser Hadoop-bootstrap dans un contexte de tests d'intégration</li>
<li>le tar.gz si le besoin est d'utiliser Hadoop-bootstrap dans son mode <em>standalone</em></li>
</ul>


<p>Pour ce faire, exécuter simplement la commande :
<code>bash
mvn install
</code></p>

<h2>Pour un fonctionnement en test d'intégration ou unitaire</h2>

<p>Pour ce mode, il est possible de faire de 2 manières différentes :</p>

<ul>
<li>démarrer les composants nécessaires manuellement</li>
<li>utiliser un wrapper qui prend en paramètre les composants à démarrer</li>
</ul>


<p>Attention cependant, dans les 2 cas, il est faut démarrer/arrêter les composants dans le bon ordre&hellip;</p>

<h3>Zookeeper</h3>

<p>```java
private static Bootstrap zookeeper;</p>

<p>BeforeClass
public static void setup() {
  zookeeper = ZookeeperBootstrap.INSTANCE.start();
}</p>

<p>@AfterClass
public static void tearDown() {
  zookeeper.stop();
}
```</p>

<p>ou</p>

<p>```java
static private HadoopBootstrap hadoopBootstrap;</p>

<p>@BeforeClass
public static void setup() throws BootstrapException {
  hadoopBootstrap = new HadoopBootstrap(Component.ZOOKEEPER);
  hadoopBootstrap.startAll();
}</p>

<p>@AfterClass
public static void tearDown() throws BootstrapException {</p>

<pre><code>hadoopBootstrap.stopAll();
</code></pre>

<p>}
```</p>

<h3>HDFS</h3>

<p>```java
private static Bootstrap hdfs;</p>

<p>BeforeClass
public static void setup() {
  hdfs = HdfsBootstrap.INSTANCE.start();
}</p>

<p>@AfterClass
public static void tearDown() {
  hdfs.stop();
}
```</p>

<p>ou</p>

<p>```java
static private HadoopBootstrap hadoopBootstrap;</p>

<p>@BeforeClass
public static void setup() throws BootstrapException {
  hadoopBootstrap = new HadoopBootstrap(Component.HDFS);
  hadoopBootstrap.startAll();
}</p>

<p>@AfterClass
public static void tearDown() throws BootstrapException {</p>

<pre><code>hadoopBootstrap.stopAll();
</code></pre>

<p>}
```</p>

<h3>HBase</h3>

<p>```java
static private Bootstrap zookeeper;
static private Bootstrap hdfs;
static private Bootstrap hbase;</p>

<p>BeforeClass
public static void setup() {
  hdfs = HdfsBootstrap.INSTANCE.start();
  zookeeper = ZookeeperBootstrap.INSTANCE.start();
  hbase = HBaseBootstrap.INSTANCE.start();
}</p>

<p>@AfterClass
public static void tearDown() {
  hbase.stop()
  zookeeper.stop()
  hdfs.stop()
}
```</p>

<p>ou</p>

<p>```java
static private HadoopBootstrap hadoopBootstrap;</p>

<p>@BeforeClass
public static void setup() throws BootstrapException {
  hadoopBootstrap = new HadoopBootstrap(Component.HDFS, Component.ZOOKEEPER, Component.HBASE);
  hadoopBootstrap.startAll();
}</p>

<p>@AfterClass
public static void tearDown() throws BootstrapException {</p>

<pre><code>hadoopBootstrap.stopAll();
</code></pre>

<p>}
```</p>

<h3>Hive</h3>

<p>```java
static private Bootstrap zookeeper;
static private Bootstrap hiveMetastore;
static private Bootstrap hiveServer2;</p>

<p>@BeforeClass
public static void setup() throws Exception {</p>

<pre><code>zookeeper = ZookeeperBootstrap.INSTANCE.start();
hiveMetastore = HiveMetastoreBootstrap.INSTANCE.start();
hiveServer2 = HiveServer2Bootstrap.INSTANCE.start();
</code></pre>

<p>}</p>

<p>@AfterClass
public static void tearDown() throws Exception {</p>

<pre><code>hiveServer2.stop();
hiveMetastore.stop();
zookeeper.stop();
</code></pre>

<p>}
```</p>

<p>ou</p>

<p>```java
static private HadoopBootstrap hadoopBootstrap;</p>

<p>@BeforeClass
public static void setup() throws BootstrapException {
  hadoopBootstrap = new HadoopBootstrap(Component.ZOOKEEPER, Component.HIVEMETA, Component.HIVESERVER2);
  hadoopBootstrap.startAll();
}</p>

<p>@AfterClass
public static void tearDown() throws BootstrapException {</p>

<pre><code>hadoopBootstrap.stopAll();
</code></pre>

<p>}
```</p>

<h3>Kafka</h3>

<p>```java
static private Bootstrap zookeeper;
static private Bootstrap kafka;</p>

<p>@BeforeClass
public static void setup() throws Exception {</p>

<pre><code>zookeeper = ZookeeperBootstrap.INSTANCE.start();
kafka = KafkaBootstrap.INSTANCE.start();
</code></pre>

<p>}</p>

<p>@AfterClass
public static void tearDown() throws Exception {</p>

<pre><code>kafka.stop();
zookeeper.stop();
</code></pre>

<p>}
```</p>

<p>ou</p>

<p>```java
static private HadoopBootstrap hadoopBootstrap;</p>

<p>@BeforeClass
public static void setup() throws BootstrapException {
  hadoopBootstrap = new HadoopBootstrap(Component.ZOOKEEPER, Component.KAFKA);
  hadoopBootstrap.startAll();
}</p>

<p>@AfterClass
public static void tearDown() throws BootstrapException {</p>

<pre><code>hadoopBootstrap.stopAll();
</code></pre>

<p>}
```</p>

<h3>SolRCloud</h3>

<p>La difficulté pour intégrer ce composant était que le mode SolR Cloud n'existait pas. Dans mon contexte d'utilisation, la cible était SolR Cloud qui impose l'utilisation de Zookeeper. Concernant l'interaction d'un client externe, il doit donc récupérer la configuration de SolR au sein de Zookeeper : le mode de fonctionnement est donc différent d'un SolR en <em>standalone</em>.</p>

<p>Pour faire fonctionner le mode SolR Cloud, il a fallu interagir directement avec Zookeeper en y écrivant les informations sur la collection cible car le mode embarqué n'offrait pas les API suffisantes pour créer une collection.</p>

<p>Actuellement, ce mode ne fonctionne qu'avec une collection qui doit être connue et renseignée préalablement (schema.xml, &hellip;).</p>

<p>```java
static private Bootstrap zookeeper;
static private Bootstrap solr;</p>

<p>@BeforeClass
public static void setup() throws Exception {</p>

<pre><code>zookeeper = ZookeeperBootstrap.INSTANCE.start();
solr = SolrCloudBootstrap.INSTANCE.start();
</code></pre>

<p>}</p>

<p>@AfterClass
public static void tearDown() throws Exception {</p>

<pre><code>solr.stop();
zookeeper.stop();
</code></pre>

<p>}
```</p>

<p>ou</p>

<p>```java
static private HadoopBootstrap hadoopBootstrap;</p>

<p>@BeforeClass
public static void setup() throws BootstrapException {
  hadoopBootstrap = new HadoopBootstrap(Component.ZOOKEEPER, Component.SOLRCLOUD);
  hadoopBootstrap.startAll();
}</p>

<p>@AfterClass
public static void tearDown() throws BootstrapException {</p>

<pre><code>hadoopBootstrap.stopAll();
</code></pre>

<p>}
```</p>

<h3>Oozie</h3>

<p>La difficulté pour intégrer ce composant était que <a href="https://github.com/sakserv/hadoop-mini-clusters">Hadoop-mini-clusters</a> ne permettait pas à un client extérieur à la JVM ayant démarré Oozie d'intéragir avec le serveur.</p>

<p>En outre, pour utiliser les action Oozie tierce, il était nécesssaire de télécharger oozie. J'ai juste simplifié ce mode en obligeant l'utilisateur à disposer déjà de oozie sur son poste pour accélérer le mode de fonctionnement.</p>

<p>Il est donc nécessaire de télécharger les <code>sharelib</code> de Oozie qui contiennet les librairies permettant de lancer des actions Hive, Spark, Shell ou autre (en fait, pour être plus précis, les sharelib sont dans la distribution d'Oozie : on télécharge donc Oozie&hellip;) : <a href="http://s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.3.2.0/tars/oozie-4.2.0.2.3.2.0-2950-distro.tar.gz">http://s3.amazonaws.com/public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.3.2.0/tars/oozie-4.2.0.2.3.2.0-2950-distro.tar.gz</a></p>

<p>Il suffit ensuite de modifier le fichier <code>default.properties</code> en y renseignant la variable <code>oozie.sharelib.path</code> avec la bonne valeur.</p>

<p>```java
static private Bootstrap hdfs;
static private Bootstrap oozie;</p>

<p>@BeforeClass
public static void setup() throws Exception {</p>

<pre><code>hdfs = HdfsBootstrap.INSTANCE.start();
oozie = OozieBootstrap.INSTANCE.start();
</code></pre>

<p>}</p>

<p>@AfterClass
public static void tearDown() throws Exception {</p>

<pre><code>oozie.stop();
hdfs.stop();
</code></pre>

<p>}
```</p>

<p>ou</p>

<p>```java
static private HadoopBootstrap hadoopBootstrap;</p>

<p>@BeforeClass
public static void setup() throws BootstrapException {
  hadoopBootstrap = new HadoopBootstrap(Component.HDFS, Component.OOZIE);
  hadoopBootstrap.startAll();
}</p>

<p>@AfterClass
public static void tearDown() throws BootstrapException {</p>

<pre><code>hadoopBootstrap.stopAll();
</code></pre>

<p>}
```</p>

<h2>Pour un fonctionnement en mode <em>standalone</em></h2>

<p>Pour ce mode de fonctionnement, il suffit de récupérer le tar.gz généré lors de la compilation. Il est <em>autoporteur</em> et il suffit de le décompresser puis de démarrer Hadoop-bootstrap.</p>

<p>Ses fichiers de configuration se trouvent dans le répertoire <code>conf</code>.</p>

<p>Afin de pouvoir choisir les composants à démarrer, il suffit de modifier le contenu du fichier <code>hadoop.properties</code> se trouvant dans le répertoire <code>conf</code>.</p>

<p>Pour démarrer l'écosystème, il suffit d'exécuter la commande suivante :</p>

<p><code>bash
./bin/hadoop-bootstrap start
</code></p>

<p>Pour arrêter hadoop-bootstrap, exécuter la commande suivante :
<code>bash
./bin/hadoop-bootstrap stop
</code></p>

<p>Pour démarrer hadoop-bootstrap en mode interactif, exécuter la commande :
<code>bash
./bin/hadoop-bootstrap console
</code></p>

<div>
<iframe allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/ef_9Y7a2ar8" width="560"></iframe></div>


<p>A noter que ces commandes fonctionnent également sous Windows.</p>

<p>Concernant macOS, je n'ai pas testé mais cela ne devrait pas poser de difficultées.</p>

<h1>Conclusion</h1>

<p><a href="https://github.com/jetoile/hadoop-bootstrap">Hadoop-bootstrap</a> n'est pas un composant révolutionnaire et ne fait que wrapper ce qui a déjà été fait dans <a href="https://github.com/sakserv/hadoop-mini-clusters">Hadoop-mini-clusters</a>.</p>

<p>Cependant, il est plus simple d'utilisation car limite plus l'utilisation des composants.</p>

<p>Il permet, en outre, d'utiliser l'écosystème Hadoop en mode <em>standalone</em> (écosystème fonctionnant, bien sûr, en mode dégradé&hellip;) et d'interagir avec avec des clients externes (par exemple, <code>hdfs dfs</code> fonctionne bien avec le hdfs démarré). Pour plus d'information, il suffit d'aller voir la classe <code>ManualIntegrationBootstrapTest</code> dans le package <code>fr.jetoile.sample.integrationtest</code>.</p>

<p>Alors, oui, ce n'est pas une révolution mais, au moins, ca permettra à l'utilisateur de ne pas à avoir à se battre avec les conflits de jar que j'ai pu avec avec SolR et Hadoop&hellip; ;)</p>

<p>Pour plus d'informations, les <a href="https://github.com/jetoile/hadoop-bootstrap/tree/master/src/test/java/fr/jetoile/sample/component">tests unitaires</a> et les <a href="https://github.com/jetoile/hadoop-bootstrap/blob/master/src/test/java/fr/jetoile/sample/integrationtest/IntegrationBootstrapTest.java">tests d'<em>intégration</em></a>.</p>

<p>A noter que pour faire fonctionner certains composants, je n'ai pas fait dans la finesse&hellip; et j'ai allègrement <em>hacké</em> certaines classes&hellip;</p>

<p>A noter également que j'ai simplement copier/coller les tests de <a href="https://github.com/sakserv/hadoop-mini-clusters">Hadoop-mini-clusters</a> sauf dans le mode intégration où je les ai un peu modifié pour permettre une connexion <em>remote</em>.</p>

<p>Voilà, ce n'est pas le plus beau code que j'ai pu faire, mais j'espère que ca pourra aider certains et, au pire, n'hésitez pas à contribuer ou à forker pour en faire ce que vous en voulez ;)</p>

<h2>Limitations connues</h2>

<ul>
<li>phoenix ne fonctionne pas (voir la branche phoenix)</li>
<li>une seule collection possible avec SolR</li>
<li>des optimisations sur Oozie sont possibles (notamment sur la partie téléchargement/décompression)</li>
</ul>

]]></content>
  </entry>
  
</feed>
