
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>

<script type="text/javascript">
    var host = "blog.jetoile.fr";
    if ((host == window.location.host) && (window.location.protocol != "https:"))
        window.location.protocol = "https";
</script>

  <meta charset="utf-8">
  <title>Sqoop Et Parquet : Mode D'emploi - Jetoile</title>
  <meta name="author" content="Khanh Maudoux">

  <meta content='blog sur Java jee' name='description'/>
  <meta content='jee, java, cloud, nosql' name='keywords'/>
  <meta content='index, follow' name='robots'/>
  <link href='url' rel='canonical'/>

  
  <meta name="description" content="Sqoop Et Parquet : Mode D'emploi November 28, 2016 Dans le monde du BigData (en l&#8217;occurence avec Hadoop), il est parfois utile de pouvoir &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="https://blog.jetoile.fr/2016/11/sqoop-et-parquet-mode-demploi.html">
  <link href="/favicon.ico" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Jetoile" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>

  <script src="/javascripts/monthly_archive.js"></script>
  <!-- font-family: 'Knewave', cursive; -->
<link href='http://fonts.googleapis.com/css?family=Knewave' rel='stylesheet' type='text/css'>
<!-- font-family: 'Cantata One', serif; -->
<link href='http://fonts.googleapis.com/css?family=Cantata+One' rel='stylesheet' type='text/css'>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-11955429-1']);
    _gaq.push(['_trackPageview']);
    _gaq.push(['_setDomainName','github.io']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

  <body>
    <a href="/" class="home-icon">
      <img src="/images/home.png"/>
    </a>

    <article role="article" class="full-single-article">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h1>Sqoop Et Parquet : Mode D'emploi</h1>
        <div class="meta">
          








  



<time datetime="2016-11-28T11:15:19+01:00" pubdate data-updated="true">November 28, 2016</time>  
        </div>
        <p><img src="/images/Apache_Sqoop_logo.svg.png" alt="left-small" /> Dans le monde du <em>BigData</em> (en l&#8217;occurence avec Hadoop), il est parfois utile de pouvoir importer le contenu d&#8217;une base de données dans son Datalake.</p>

<p>Pour ce faire, <a href="http://sqoop.apache.org/">Apache Sqoop</a> est une des alternatives pour le faire (peut être pas la meilleure mais bon&hellip;).</p>

<p>En effet, Sqoop permet d&#8217;importer (et exporter également) les données d&#8217;une base de données dans :</p>

<ul>
<li>hdfs au format <em>plain text</em>, sequencefile, avro ou parquet</li>
<li>hive</li>
<li>hbase</li>
</ul>


<p>En outre, il permet d&#8217;avoir un mode incrémental afin de gérer le mode delta.</p>

<p>Cependant, comme on le verra dans cet article, Sqoop n&#8217;est pas aussi trivial qu&#8217;il peut le paraitre.</p>

<p>C&#8217;est ce qui sera détaillé dans cet article : à savoir une sorte de mini retour d&#8217;expérience&hellip; et heureux en plus ;)</p>

<!--more-->


<h1>Cas d&#8217;usage</h1>

<p>Techniquement, voilà ce qui est souhaité concernant l&#8217;import des données dans hdfs :</p>

<ul>
<li>pouvoir ingérer le contenu d&#8217;une base de données dans hdfs au format parquet ou avro,</li>
<li>pouvoir ingérer les données de la table en mode incrémental,</li>
<li>pouvoir préciser la requête avec <code>--query</code> en raison que la colonne utilisée par le <code>--split-by</code> dispose d&#8217;un index partitionné.</li>
</ul>


<p>Pour être plus précis sur les besoins, la volonté de disposer des données au format parquet ou avro est liée au besoin d&#8217;effectuer des traitements Spark simplement (par exemple, pouvoir repartitionner les données en fonction d&#8217;un certain nombre de colonne).</p>

<p>En outre, concernant le mode incrémental, cela est lié au fait que des données sont reçues quotidiennement et que des traitements sont effectués à l&#8217;aide de PL/SQL (<em>no comment&hellip;</em>). Heureusement, il peut être considérer que les informations reçues/calculées sont seulement ajoutées aux tables.</p>

<p>Enfin, afin de permettre la parallélisation du traitement, plusieurs <em>mappers</em> seront utilisés. Afin de permettre le calcul des <em>ranges</em> affectés à chacun des <em>mappers</em>, il est nécessaire de préciser l&#8217;option <code>--split-by</code>. Cependant, dans notre cas d&#8217;usage, la colonne utilisée pour le split-by dispose d&#8217;un index mais est partitionné. Etant donné qu&#8217;il n&#8217;est pas possible (toujours dans notre cas précis) de préciser l&#8217;option <code>--boundary-query</code>, c&#8217;est donc le comportement par défaut qui est appliqué (à savoir un <code>select min(&lt;split-by&gt;), max(&lt;split-by&gt;)</code>). Cependant, attaquer la table sans préciser la partition implique que notre temps d&#8217;exécution du min/max dure plusieurs heures, chose non acceptable dans le cas du fonctionnement incrémental.</p>

<p>Aussi, il a été décidé d&#8217;ingérer la table partition par partition en précisant la partition à chaque fois avec l&#8217;option <code>--query</code> (à noter que l&#8217;option <code>--where</code> aurait pu suffire mais que cela n&#8217;a pas été testé).</p>

<h1>Mise en oeuvre</h1>

<p>Afin de mettre en oeuvre notre cas d&#8217;usage, plusieurs expérimentations on été effectuées.</p>

<p>Dans ce chapitre, il sera expliqué ce qui a pu être constaté ainsi que les <em>workaround</em> qui ont été trouvées lorsqu&#8217;un soucis se présentait.</p>

<h2>Import au format parquet ou avro</h2>

<p>En fait, lorsque la commande <code>sqoop import</code> est utilisée avec les options <code>--as-avrodatafile</code> ou <code>--as-parquetfile</code>, les données récupérées sont toutes de type string. Aussi, il est nécessaire de préciser le type de chaque colonne avec l&#8217;option <code>--map-column-java</code>. Pour trouver le typage de chaque colonne, une simple requête jdbc a été effectuée afin de trouver les colonnes et leurs types.</p>

<h2>Import incrémental</h2>

<p>Le mode incrémental ne supportant pas le format avro, il a donc été écarté et l&#8217;import s&#8217;est fait au format parquet.</p>

<h2>Parallélisation de l&#8217;import</h2>

<p>En fait, le fait de préciser la requête d&#8217;import avec sqoop 1.4.6 en mode parquet est buggé&hellip;
En effet, il existe 2 <em>issues</em> qui traitent de ce problème :</p>

<ul>
<li><a href="https://issues.apache.org/jira/browse/SQOOP-2582">SQOOP-2582</a> &ndash; Query import won&rsquo;t work for parquet</li>
<li><a href="https://issues.apache.org/jira/browse/SQOOP-2408">SQOOP-2408</a> &ndash; Sqoop doesnt support &mdash;as-parquetfile with -query option.</li>
</ul>


<p>Après avoir appliqué les 2 patchs et recompilé Sqoop (avec un joli <code>ant package -Dhadoopversion=210</code>, le verdict tombe&hellip; : une erreur kite.</p>

<p>Heureusement, une montée de version de kite directement dans le lib de sqoop permet de faire fonctionner l&#8217;import (ie. remplacer <code>kite-data-core-1.0.0.jar</code> par <code>kite-data-core-1.1.0.jar</code>, <code>kite-data-hive-1.0.0.jar</code> par <code>kite-data-hive-1.1.0.jar</code>, <code>kite-data-mapreduce-1.0.0.jar</code> par <code>kite-data-mapreduce-1.1.0.jar</code> et <code>```kite-hadoop-compatibility-1.0.0.jar</code> par <code>kite-hadoop-compatibility-1.1.0.jar</code>).</p>

<h1>Conclusion</h1>

<p>Ce mini retour d&#8217;expérience sur l&#8217;utilisation de Sqoop (dans sa version 1.4.6) a permis de voir qu&#8217;il était tout à fait possible d&#8217;importer des données d&#8217;une base de données dans hdfs au format parquet.</p>

<p>Cependant, il semble que, pour l&#8217;instant, Sqoop manque <em>un peu</em> de maturité avec Parquet et trouver des contournements pour faire fonctionner le tout n&#8217;est pas des plus trivial mais heureusement, cela fonctionne ;)</p>

<p>A noter que dans notre cas d&#8217;usage, il n&#8217;y avait pas, bien sûr, qu&#8217;une seule table mais plusieurs centaines.</p>


<footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Khanh Maudoux</span></span>

      </p>
      <p class="meta">
      








  



<time datetime="2016-11-28T11:15:19+01:00" pubdate data-updated="true">November 28, 2016</time> in 

<span class="categories">
  
    <a class='category' href='/blog/categories/hadoop/'>Hadoop</a>, <a class='category' href='/blog/categories/parquet/'>Parquet</a>, <a class='category' href='/blog/categories/sqoop/'>Sqoop</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="https://blog.jetoile.fr/2016/11/sqoop-et-parquet-mode-demploi.html" data-via="jetoile" data-counturl="https://blog.jetoile.fr/2016/11/sqoop-et-parquet-mode-demploi.html" >Tweet</a>
  
  
  <div class="g-plusone" data-size="medium"></div>
  
  
</div>

    
</footer>

<!--
<section>
<h1>Comments</h1>
<script>
var idcomments_acct = '1a2a89d3b135fb1f774e938fd286d920';
var idcomments_post_id;
var idcomments_post_url;
</script>
<span id="IDCommentsPostTitle" style="display:none"></span>
<script type='text/javascript' src='http://www.intensedebate.com/js/genericCommentWrapperV2.js'></script>

</section>
-->


  <section>
    <h1>Comments</h1>

    <!--
<div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'jetoile'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
-->

<div id="disqus_thread"></div>
  

<script type="text/javascript">
      var disqus_shortname = 'jetoile';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'https://blog.jetoile.fr/2016/11/sqoop-et-parquet-mode-demploi.html';
        var disqus_url = 'https://blog.jetoile.fr/2016/11/sqoop-et-parquet-mode-demploi.html';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>


  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>

  </section>


      </div>
    </div>
  </div>



</article>

<hr class="divider-short"/>

<div class="archive-link">
  <div class="container">
    <div class="row">
      <a class="pull-center" href="/" title="Home">Home</a>
    </div>
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        
          <a class="pull-left" href="/2016/05/hadoop-unit-1-dot-3.html" title="Previous Post: Hadoop Unit 1.3">&laquo; Previous: Hadoop Unit 1.3</a>
        

        
          <a class="pull-right" href="/2017/07/tester-avec-elasticsearch.html" title="Next Post: Des tests d'intégration avec Elasticsearch">Next: Des tests d'intégration avec Elasticsearch &raquo;</a>
        
      </div>
    </div>
  </div>
</div>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
<script type="text/javascript">
  window.___gcfg = {lang: 'fr'};

  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/platform.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script>

    <footer id="footer" class="her-row">
  <div class="container">
    <div class="row">
      <div id='footer-shadow'></div>
<!--//please give me a respect for keep these credits line -->
<div class='credits'>
<div align='center'>

<table style="border:none;border-spacing: 20px;border-collapse: separate;">
<tr style="border:none">
<td style="border:none">
<a href="http://twitter.com/jetoile" class="twitter-follow-button" data-show-count="false" data-lang="fr">Follow @jetoile</a>
<script src="http://platform.twitter.com/widgets.js" type="text/javascript"></script>
</td>
<td style="border:none">
<a href="https://plus.google.com/u/0/114765959876500830478/posts?prsrc=3" style="text-decoration: none; color: #333;"><div style="display: inline-block;"><span style="float: left; font: bold 13px/16px arial,sans-serif; margin-right: 4px; margin-top: 7px;">khanh</span><span style="float: left; font: 13px/16px arial,sans-serif; margin-right: 11px; margin-top: 7px;">on</span><div style="float: left;"><img src="/images/gplus-32.png" width="32" height="32" style="border: 0;"/></div><div style="clear: both"></div></div></a>
</td>
<td style="border:none">
<a href="http://fr.linkedin.com/pub/khanh-tuong-maudoux/19/92b/11b"><img src="/images/btn_profile_bluetxt_8
0x15_fr_FR.png" width="80" height="15" border="0" alt="Voir le profil de Khanh Tuong Maudoux sur LinkedIn" /></a>
</td>
</tr>
</table>


<img alt='Jetoile' height='50' src='/images/logoJetoile_v51.png' style='border-width:0; vertical-align: middle' width='180'/>
<p>&#169; 2011 <a href='http://blog.jetoile.fr/'>Je toile ou j* au choix...</a> - Khanh Maudoux</p>
<a href='http://creativecommons.org/licenses/by/4.0/' rel='license'><img alt='Licence Creative Commons' src='/images/creative_common88x31.png' style='border-width:0'/></a> Cette œuvre de <a href='http://blog.jetoile.fr' property='cc:attributionName' rel='cc:attributionURL' xmlns:cc='http://creativecommons.org/ns#'>http://blog.jetoile.fr</a> est mise à disposition selon les termes de la <a href='http://creativecommons.org/licenses/by/4.0/' rel='license'>licence Creative Commons Attribution 4.0 International</a>.
<!--img alt='Creative Commons License' src='http://i.creativecommons.org/l/by/2.0/fr/88x31.png' style='border-width:0; vertical-align: middle;'/> <small>Sauf mention contraire, le contenu de ce blog est mis à disposition selon les termes de la licence <a href='http://creativecommons.org/licenses/by/2.0/fr/'>Creative Commons Attribution 2.0 License</a>.</small-->
<br/>
<small>Powered by <a href="http://octopress.org">Octopress</a><br/>
</small>
</div>
</div>


    </div>
  </div>
</footer>

  </body>
</html>
