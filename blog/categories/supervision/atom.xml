<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: supervision | Jetoile]]></title>
  <link href="https://blog.jetoile.fr/blog/categories/supervision/atom.xml" rel="self"/>
  <link href="https://blog.jetoile.fr/"/>
  <updated>2017-11-03T20:15:31+01:00</updated>
  <id>https://blog.jetoile.fr/</id>
  <author>
    <name><![CDATA[Khanh Maudoux]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Logstash : tour d'horizon sur les stratégies de déploiement]]></title>
    <link href="https://blog.jetoile.fr/2014/04/logstash-petit-tour-dhorizon.html"/>
    <updated>2014-04-07T11:20:26+02:00</updated>
    <id>https://blog.jetoile.fr/2014/04/logstash-petit-tour-dhorizon</id>
    <content type="html"><![CDATA[<p><img src="/images/logstash/logstash.png" alt="left-small" />
Cet article fera un rapide tour d'horizon sur les différentes stratégies qui peuvent être utilisées pour <a href="http://logstash.net/">Logstash</a>.</p>

<p>Pour ce faire, je m'appuierai sur le très bon <a href="http://www.logstashbook.com/">livre officiel</a> que je me suis procuré (moyennant environ 10€) et qui fournit une très bonne vision sur ce qui est possible de faire ainsi que sur les différents concepts mais également sur les différentes stratégies de déploiement.</p>

<p>Même si je résumerai succinctement quelques-uns des concepts afin que cet article soit un minimum compréhensible, cet article traitera surtout sur la façon dont il est possible de déployer les agents Logstash.</p>

<p>[<em>ndlr</em> : par contre, je ne ferai, comme à mon habitude, que retranscrire ce qui est présent dans le livre&hellip;]</p>

<!-- more -->


<h1>Les concepts</h1>

<p>Logstash est écrit en JRuby et fonctionne dans une JVM. Son architecture est orientée messages et est très simple. Plutôt que de séparer le concepts d'agents et de serveurs, Logstash se présente comme  un simple agent qui est configuré pour combiner différentes fonctions avec d'autres composants open souce.</p>

<p>L'écosystème de Logstash est constitué de 4 composants :</p>

<ul>
<li><strong>Shipper</strong> qui envoie des événements à Logstash.</li>
<li><strong>Broker</strong> et <strong>Indexer</strong> qui reçoivent et indexent les événements.</li>
<li><strong>Search</strong> et <strong>Stockage</strong> qui permettent de rechercher et de stocker les événements.</li>
<li><strong>Web Interface</strong> qui est une interface web appelée <a href="http://www.elasticsearch.org/overview/kibana/"><strong>Kibana</strong></a>.</li>
</ul>


<p>Les serveurs Logstash sont constitués d'un ou de plusieurs de ces composants indépendamment, ce qui permet de les séparer offrant ainsi la possibilité de <em>scaler</em>  mais également de les combiner en fonction du besoin.</p>

<p>Dans le plupart des cas, Logstash sera déployé de la manière suivante :</p>

<ul>
<li>Les hôtes exécutant les agent Logstash comme des <strong>Shipper</strong> qui émettent, comme des événements, les logs des applications, services et hôte à un serveur central Logstash. Ces hôtes n'ont besoin de disposer que d'agents Logstash.</li>
<li>Le serveur central Logstash qui aura à sa charge l'exécution du <strong>Broker</strong>, <strong>Indexer</strong>, <strong>Search</strong>, <strong>Storage</strong> et <strong>Web Interface</strong> afin de recevoir, <em>processer</em> et stocker les logs.</li>
</ul>


<p><img src="/images/logstash/archi01.png" alt="center" /></p>

<p>En fait, une configuration typique de Logstash est la suivante :</p>

<p>```text
input {
  stdin { }
}</p>

<p>filter {
  grok {</p>

<pre><code>match =&gt; { "message" =&gt; "%{COMBINEDAPACHELOG}" }
</code></pre>

<p>  }
  date {</p>

<pre><code>match =&gt; [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
</code></pre>

<p>  }
}</p>

<p>output {
  elasticsearch { host => localhost }
  stdout { codec => rubydebug }
}
```</p>

<p>où :</p>

<ul>
<li><code>input</code> peut prendre en valeur des <em>plugins</em> qui correspondent à ce que peut prendre en entrée l'agent (comme, par exemple, l'entrée standard ou le contenu d'un fichier).</li>
<li><code>filter</code> peut prendre en valeur des <em>plugins</em> qui permettent de manipuler l'événement en le <em>parsant</em>, filtrant ou en ajoutant des informations issues du parsing ou non.</li>
<li><code>output</code> peut prendre en valeur des <em>plugins</em> qui permettent de préciser où seront envoyés les événements (comme, par exemple, la sortie standard ou ElasticSearch).</li>
</ul>


<h1>Les différentes stratégies de déploiement possibles</h1>

<h2>Le mode de déploiement <em>classique</em></h2>

<p>Dans l'architecture de déploiement <em>classique</em>, on retrouve la <em>stack</em> préconisée qui est la suivante :</p>

<ul>
<li>Les agents Logstash se trouvant sur les machines hôtes collectent et émettent les logs (sous forme d'événements) au système central.</li>
<li>Une instance d'un système de bufferisation (comme <a href="http://redis.io/"><strong>Redis</strong></a> ou autre, comme une implémentation d'<a href="http://www.amqp.org/"><strong>AMQP</strong></a>) reçoit les événement sur le serveur central et joue le rôle de buffer.</li>
<li>Un agent Logstash extrait les événements de logs du buffer et les traite.</li>
<li>L'agent Logstash envoie les événements d'index dans ElasticSearch.</li>
<li>ElasticSearch stocke et rend les événements cherchable.</li>
<li>Kibana permet la recherche et le rendu des événements indexés dans ElasticSearch.</li>
</ul>


<p><img src="/images/logstash/archi02.png" alt="center" /></p>

<p>En fait, le <strong>broker</strong> permet de servir de buffer entre les agents et le serveur Logstash. Cela est essentiel pour les raisons suivantes :</p>

<ul>
<li>Cela permet d'améliorer les performances de l'environnement Logstash en fournissant une buffer de cache pour les événements de log.</li>
<li>Cele permet de fournir de la résiliance. Si l'indexation Logstash échoue, alors les événements sont mise en fils d'attente afin d'éviter la perte d'informations.</li>
</ul>


<p>On observe donc, dans cette configuration, que les agents Logstash présents sur les machines hôtes ne font que transmettre sans intelligence réelle au buffer les différents événements de log et qu'ils n'ont pas <em>vraiment</em> de logique (ie. ils n'ont pas de section <strong>filter</strong> mais juste les sections <strong>input</strong> et <strong>output</strong>).</p>

<h2>Le mode de déploiement sans agent</h2>

<h3>A la mode système</h3>

<p>Comme on a pu voir dans le paragraphe précédent, les machines hôtes disposent d'un agent Logstash complet. Cependant, ils n'ont pas vraiment de logique puisqu'ils ne font que transmettre les événements de logs au broker dont le rôle est de servir de buffer.</p>

<p>Cependant, parfois, il peut être intéressant de ne pas à avoir besoin d'installer un agent Logstash sur les machines hôtes :</p>

<ul>
<li>si la JVM déployé sur la machine hôte est limitée,</li>
<li>si la machine hôte est un périphérique qui dispose de peu de ressource et qu'il n'est pas possible d'y installer une JVM ou d'exécuter un agent,</li>
<li>s'il n'est pas possible d'installer n'importe quel logiciel sur la machine hôte.</li>
</ul>


<p>Pour répondre à cette problématique, il est possible d'utiliser des outils systèmes comme <strong>Syslog</strong>.</p>

<p>Dans ce cas, le serveur Logstash n'aura qu'à déclarer un <em>input</em> supplémentaire permettant d'écouter des événéments (dans notre cas, Syslog).</p>

<p>A titre informatif, il est possible d'utiliser un <em>Appender</em> syslog dans log4j ou logback (entre autre).</p>

<p><img src="/images/logstash/archi03.png" alt="center" /></p>

<h3>A la mode agent</h3>

<p>Dans le cas où ni un agent Logstash ni Syslog ne sont envisageables, il est possible d'utiliser <a href="https://github.com/elasticsearch/logstash-forwarder">Logstash Forwarder</a> (anciennement Lumberjack).</p>

<p>Il s'agit d'un client légé permettant d'envoyer des messages à Logstash en offrant un protocole maison intégrant de la sécurité (encryption SSL) ainsi que de la compression.</p>

<p>Il a été conçu pour être petit avec une faible emprunte mémoire tout en étant rapide. Il a été écrit en <a href="http://golang.org/">Go</a>.</p>

<p>Dans ce cas, il suffit d'exécuter logstash-forwarder avec les <em>bons</em> fichiers de configuration spécifiant l'adresse du serveur cible ainsi que l'emplacement du certificat et les fichiers à scruter.</p>

<p>Du coté serveur, il suffit, tout comme pour le mode sans agent à base de Syslog, de déclarer un <em>input</em> lumberjack.</p>

<p>A noter que d'autres <em>shipper</em> sont également disponibles tels que :</p>

<ul>
<li><a href="https://github.com/josegonzalez/beaver">Beaver</a></li>
<li><a href="https://github.com/danryan/woodchuck">Woodchuck</a></li>
</ul>


<h1>Les filtres</h1>

<p>Logstash vient avec un système de filtre qu'il est possible de configurer via la section <strong>filter</strong>.</p>

<p>Ces filtres permettent de filtrer mais également de modifier (via <strong>mutable</strong>) le contenu de l'événement. Ils permettent également de <em>parser</em> les événements (via <strong>grok</strong>) afin de les rajouter lors de la phase d'indexation (et donc de stockage). Cela permet ainsi de pouvoir rechercher des événements de manière plus ciblé.</p>

<p>Il existe plusieurs stratégies lors de l'utilisation de filtres :</p>

<ul>
<li>filtrer les événements sur l'agent,</li>
<li>filtrer les événements sur le serveur central,</li>
<li>émettre les événements au bon format.</li>
</ul>


<p>Le plus simple est encore d'émettre les logs au bon format, cependant, cela n'est pas toujours possible (trop de log différents, systèmes hétérogènes, code legacy, &hellip;).</p>

<p>Une autre manière de faire est d'exécuter le filtrage localement (ie. directement sur l'agent). Cela permet de réduire la charge de traitement du serveur central et d'être sûr que seuls les événements propres et structurés seront stockés. Cependant, cela oblige à maintenir une configuration plus complexe sur chaque agent.</p>

<p>A l'inverse, si le filtrage est effectué sur le serveur central, cela permet de centraliser les filtres et permet donc une administration plus simple. Cependant, cela demande des ressources supplémentaires pour effectuer le filtrage sur un plus grand nombre d'événements.</p>

<h1>La scalabilité et Logstash</h1>

<p>Une des grande force de Logstash est qu'il est possible de le composer avec différents composants : Logstash lui-même, Redis comme <em>broker</em>, ElasticSearch et bien d'autres éléments qu'il est possible de composer via la configuration de Logstash.</p>

<p>Ainsi, il est possible de jouer à plusieurs niveaux pour répondre à telles ou telles problématiques comme la perte de messages, le fait d'avoir un SPOF (<em>Single Point Of Failure</em>) ou d'avoir un point de contention dans le système.</p>

<p>Par exemple, si Redis est utilisé comme broker entre les agents Logstash et le serveur central, il peut être intéressant de passer Redis en mode <em>failover</em> afin d'éviter une perte d'événements lors de la transmission de ces derniers. Pour ce faire, il suffit de configurer le plugin <strong>redis</strong> de la section <strong>output</strong>  avec l'option <code>shuffle_hosts</code> pour indiquer à l'agent Logstash de n'utiliser qu'un seul noeud Redis lors de sa phase d'écriture. Du coté du serveur central, il suffit d'ajouter (et de configurer) autant de plugin <strong>redis</strong> de la section <strong>input</strong> que de noeud.</p>

<p><img src="/images/logstash/archi04.png" alt="center" /></p>

<p>Afin de permettre à la partie stockage/indexation d'être scalable, il suffit de configurer ElasticSearch en mode cluster, ce qui est natif chez lui.</p>

<p>Enfin, il est possible de rendre le serveur central Logstash robuste à la panne en en créant d'autres instances (mode <em>failover</em>) qui partageront la même configuration.</p>

<p><img src="/images/logstash/archi05.png" alt="center" /></p>

<h1>Conclusion</h1>

<p>En conclusion de cet article où je ne suis pas rentré dans les détails (mais ce n'est pas ce qui m'intéressait&hellip;), on peut constater qu'il existe moultes façons de configurer Logstash (et son écosystème) qui dépendent à chaque fois des besoins.</p>

<p>Cela est rendu possible par l'architecture et la conception modulaire de Logstash et le fait qu'il est très simple de le <em>plugger</em> à différentes solutions.</p>

<p>Même si cela est évident, je trouvais utile de le marquer noir sur blanc dans un court article&hellip; ;&ndash;)</p>

<h1>Pour aller plus loin&hellip;</h1>

<ul>
<li><a href="http://logstash.net/">http://logstash.net/</a></li>
<li><a href="http://www.logstashbook.com/">http://www.logstashbook.com/</a></li>
<li><a href="http://blog.xebia.fr/2013/12/12/logstash-elasticsearch-kibana-s01e02-analyse-orientee-business-de-vos-logs-applicatifs/">http://blog.xebia.fr/2013/12/12/logstash-elasticsearch-kibana-s01e02-analyse-orientee-business-de-vos-logs-applicatifs/</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
