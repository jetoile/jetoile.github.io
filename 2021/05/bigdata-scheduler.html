<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.83.1" />

  <title>Big Data et Scheduler : Reflexion &middot; Jetoile</title>

    

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://blog.jetoile.fr/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://blog.jetoile.fr/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://blog.jetoile.fr/css/blackburn.css">

  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css">

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel="stylesheet" type="text/css">

  
  <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/styles/androidstudio.min.css">
  <script async src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/highlight.min.js"></script>
  
  <script async src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://blog.jetoile.fr/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://blog.jetoile.fr/css/my.css">
    
  
  
    
        <script src="https://blog.jetoile.fr/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://blog.jetoile.fr/">Jetoile</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/post.html"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/about.html"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/contact.html"><i class='fa fa-phone fa-fw'></i>Contact</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/hadoop-unit"><i class='fa fa-list fa-fw'></i>Hadoop Unit</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/jetoile" rel="me" target="_blank"><i class="fab fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/jetoile" rel="me" target="_blank"><i class="fab fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/khanh-tuong-maudoux-11b92b19" rel="me" target="_blank"><i class="fab fa-linkedin fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/jetoile" rel="me" target="_blank"><i class="fab fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small><a href='http://creativecommons.org/licenses/by/4.0/' rel='license'><img alt='Licence Creative Commons' src='https://blog.jetoile.fr/images/creative_common88x31.png' style='border-width:0'/></a></small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Big Data et Scheduler : Reflexion</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>18 May 2021</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://blog.jetoile.fr/tags/bigdata">bigdata</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://blog.jetoile.fr/tags/scheduler">scheduler</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://blog.jetoile.fr/tags/architecture">architecture</a>
    
  </div>
  
  

</div>

  <p><img src="https://blog.jetoile.fr/images/hadoop-all.png" alt="left-small">
Dans le monde Big Data, rapidement se pose un certain nombre de besoins.</p>
<p>Besoins qui, pris unitairement, sont déjà complexes à résoudre mais qui, mis bout à bout, s&rsquo;avèrent encore plus difficiles à intégrer.</p>
<p>Parmi ces besoins, on peut citer, par exemple, les besoins de qualité de données ou de linéage (problématiques qui peuvent être regrouper sous le terme de <em>data governance</em>).</p>
<p>Cet article n&rsquo;a pas pour objectif de fournir une solution clé en main ni de parler d&rsquo;outils déjà existant mais plutôt de poser différentes réflexions que j&rsquo;ai pu avoir afin de savoir si elles avaient un sens&hellip;</p>
<!-- more -->
<h1 id="besoins">Besoins</h1>
<p>Lorsque l&rsquo;on est confronté au Big Data, les besoins qui en découlent sont les suivants :</p>
<ul>
<li>avoir un <strong>scheduler</strong> scalable permettant d&rsquo;exécuter et ordonnancer les différents jobs (qu&rsquo;ils soient MapReduce, Spark, Hive ou autres) mais également exécuter des actions qui leurs sont associées (déplacement de fichiers/répertoires, création/suppression/modification de tables hive, création de fichiers _SUCCESS, appliquer une politique de rétention, etc.)</li>
<li>avoir un <strong>catalogue de données</strong> (afin de connaître ses datasets) pour pouvoir retrouver l&rsquo;information</li>
<li>disposer d&rsquo;un <strong>lineage de données</strong> (afin de pouvoir savoir à partir de quel dataset est issu tel autre)</li>
<li>avoir de la <strong>qualité de données</strong></li>
</ul>
<div class="note">
<p>A noter que quand il est fait mention de <strong>scheduler</strong>, il ne s&rsquo;agit pas de cluster manager comme Yarn, Mesos ou k8s mais d&rsquo;un orchestrateur de tâches comme Oozie ou Airflow (pour ne citer qu&rsquo;eux).</p>
</div>
<p>Si nous revenons plus précisément sur certains de ces points, <strong>le lineage de données</strong> et la <strong>qualité de données</strong> méritent qu&rsquo;on s&rsquo;y arrête un peu plus longtemps.</p>
<p>Concernant le <strong>lineage de données</strong>, cela est intéressant de savoir à partir de quel dataset un dataset est issu mais il peut également être utile de disposer d&rsquo;un <strong>lineage de traitement</strong>, c&rsquo;est-à-dire savoir quel job a produit quel dataset. En effet, cela permet de facilement savoir, si un dataset a, par exemple, mal été produit, quel est le job dans la chaîne qui est fautif.</p>
<p>De même, dans un contexte de véracité ou d&rsquo;audit, pouvoir prouver que tel traitement produit bien le résultat voulu peut être primordial.</p>
<p>En outre, en plus d&rsquo;avoir un <strong>lineage de données</strong> portant sur le dataset, il peut être intéressant d&rsquo;avoir un lineage de données portant sur le contenu du dataset. En effet, connaître la propagation d&rsquo;une information (ou d&rsquo;un champ) de manière plus fine peut être nécessaire.</p>
<p>Pour ce qui concerne la <strong>qualité de données</strong>, cela lève différentes interrogations :</p>
<ul>
<li>que faire lorsque la donnée produite ne respecte pas le contrat (car oui, il s&rsquo;agit bien d&rsquo;un contrat au sens pré-condition/post-condition) :
<ul>
<li>doit-on arrêter la chaîne de traitement?</li>
<li>doit-on lever une alerte et continuer le traitement? et si oui, que faire de la donnée ignorée/mal produite (doit-on faire une <em>dead letter queue</em> sur la donnée en amont ou en aval?, quelle est la politique de traitement de cette <em>dead letter queue</em>?, etc&hellip;)?</li>
</ul>
</li>
<li>doit-on être pro-actif (ie. faire une vérification avant/après l&rsquo;exécution de la transformation) ou le faire de manière lazy/asynchrone?</li>
<li>comment doit être exprimé le contrat et qui (au sens traitement) doit vérifier la véracité de ce dernier?</li>
<li>si une même opération doit être appliquée sur différents datasets à différentes étapes du <em>pipeline</em> de traitement, comment s&rsquo;assurer qu&rsquo;elle soit consistante (ie. exécuter de la même manière) et cela malgré l&rsquo;utilisation de différentes technologies?</li>
</ul>
<div class="note">
<p>A noter que lorsqu&rsquo;il est fait mention de <strong>qualité de données</strong>, il s&rsquo;agit surtout de vérifier la consistance de la donnée sur un périmètre restreint et simple.</p>
<p>En effet, y intégrer des vérifications plus larges tels que des règles métiers, un croisement de différents datasets ou même  d&rsquo;y appliquer un modèle issu de <em>machine learning</em> sort du périmètre de cet article et s&rsquo;avère difficile à exprimer.</p>
<p>En outre, de tels traitements sont généralements réalisés à posteriori.</p>
</div>
<p>Bref, plus de questions que de réponses&hellip; mais qu&rsquo;il est important de se poser.</p>
<p>Aussi, le besoin peut maintenant être exprimé de la manière suivante :</p>
<ul>
<li>avoir un <strong>scheduler</strong></li>
<li>avoir un <strong>catalogue de données</strong></li>
<li>disposer d&rsquo;un <strong>lineage de données</strong> au niveau du dataset</li>
<li>disposer d&rsquo;un <strong>lineage de données</strong> au niveau du champ</li>
<li>disposer d&rsquo;un <strong>lineage de traitement</strong></li>
<li>avoir de la <strong>qualité de données</strong> :
<ul>
<li>disposer d&rsquo;un moyen pour exprimer le contrat à respecter</li>
<li>disposer d&rsquo;un moyen pour exprimer le comportement à avoir si le contrat n&rsquo;est pas respecté</li>
</ul>
</li>
</ul>
<h1 id="constat">Constat</h1>
<h2 id="scheduler">Scheduler</h2>
<p>Si on revient sur la partie <strong>scheduler</strong>, un constat peut être fait concernant les solutions les plus souvent utilisées/connues (airflow ou oozie pour n&rsquo;en citer que quelques-unes) : elles sont verbeuses (au sens <em>don&rsquo;t repeat yourself</em>).</p>
<p>Afin de permettre à l&rsquo;orchestrateur de calculer/représenter son <em>DAG</em> (Directed Acyclic Graph) d&rsquo;exécution, il faut :</p>
<ul>
<li>indiquer/représenter les input et output des jobs</li>
<li>ajouter les pre/post actions à exécuter (à noter que la vérification des conditions de l&rsquo;exécution d&rsquo;un job peut être vu comme un pré-action)</li>
</ul>
<p>Pourtant, devoir indiquer/représenter les input/output d&rsquo;un job est déjà exprimé dans le job en lui-même (par exemple, si on prend un job Spark, afin de pouvoir consommer/produire un RDD/DataSet/DataFrame, il faut effectuer une opération de lecture/écriture explicite. De même pour une requête SQL où ces informations apparaissent).</p>
<p>Concernant les pre/post actions, une grande majorité d&rsquo;entre elles peuvent être déduite du job : par exemple, on ne peut lire une donnée non présente. Ainsi devoir l&rsquo;exprimer au niveau du <strong>scheduler</strong> est redondant.</p>
<p>De même si on <em>sait</em> que le job <em>doit</em> créer/ajouter la partition hive pour la donnée produite, devoir le re-préciser pour chaque job au niveau du scheduler est dommageable.</p>
<p>Si un alter table hive (dans le cas où un nouveau champ venait à être produit) ou une politique de rétention doivent être effectués, nous y reviendrons un peu plus tard&hellip; 😜</p>
<p>Bref, on peut donc constater que la majorité des choses qui doivent être exprimées dans le scheduler sont redondantes.</p>
<h2 id="catalogue-de-données">Catalogue de données</h2>
<p>Le catalogue de données permet de connaître l&rsquo;ensemble des datasets du système. Afin de le peupler, plusieurs approches sont possibles :</p>
<ul>
<li>utiliser directement le metastore hive comme étant le catalogue de données</li>
<li>dissocier le catalogue de données du métastore hive</li>
</ul>
<p>Dissocier le catalogue de données du métastore hive apporte plusieurs avantages :</p>
<ul>
<li>le découplage</li>
<li>la possibilité d&rsquo;ajouter d&rsquo;autres types d&rsquo;informations plus méta que ce qui est permis via le metastore (documentation, &hellip;)</li>
</ul>
<p>Cependant, cela demande à avoir à le maintenir/synchroniser et, pour cela, plusieurs approches sont possibles :</p>
<ul>
<li>une approche <em>lazy</em> c&rsquo;est à dire un mécanisme allant scruter le metastore hive (que cela soit fait en positionnant un <em>listener</em> directement sur ce dernier ou via un job allant l&rsquo;interroger)</li>
<li>une approche plus <em>invasive</em> qui consiste à coupler fortement les jobs en leur demandant d&rsquo;aller renseigner le catalogue de données</li>
<li>une approche <em>entre deux</em> qui consiste à s&rsquo;appuyer sur l&rsquo;observabilité des jobs</li>
</ul>
<p>En outre, vient se poser la question de la <em>véracité</em> du métastore hive. En effet, le metastore hive est une projection du dataset qui peut être incomplète puisqu&rsquo;on est en fonctionnement <em>schema on read</em>. Le dataset réel peut donc être plus complet que ce qui est déclaré dans le metastore (le cas des <em>view</em> n&rsquo;est, ici, pas pris en compte) (à noter que l&rsquo;utilisation de SparkSQL permet de réduire la chance de diverger).</p>
<h2 id="linéage-de-données">Linéage de données</h2>
<p>Le <strong>lineage de données</strong> est une problématique non triviale et est parfois faite de manière déclarative (et donc non à jour&hellip;).</p>
<p>Cependant, les jobs disposent de l&rsquo;information et il est donc possible de ré-aggréger cette dernière de manière pro-active ou non afin de disposer d&rsquo;un linéage (au moins le lineage de dataset).</p>
<p>Bien sûr disposer de nombreuses technologies de traitement rend cela plus complexe.</p>
<p>Une autre approche pourrait consister à corréler les accès au metastore hive et le plan d&rsquo;exécution des jobs mais il se pose alors la même question de la complétude de l&rsquo;information que pour le <strong>catalogue de données</strong>.</p>
<p>Concernant le linéage de données au niveau champ, cela s&rsquo;avère assez compliqué.</p>
<h2 id="linéage-de-traitement">Linéage de traitement</h2>
<p>Disposer d&rsquo;un <strong>linéage de traitement</strong> complet (ie. pas seulement avec une vision d&rsquo;un <em>workflow</em> donné) peut s&rsquo;avérer complexe avec les scheduler actuels.</p>
<p>En outre, si plusieurs technologies de scheduler sont utilisées ou si il en existe plusieurs instances, le manque d&rsquo;API/interface commune rend l&rsquo;extraction et la corrélation difficile.</p>
<h2 id="qualité-de-données">Qualité de données</h2>
<p>La <strong>qualité de données</strong> est souvent effectuée a posteriori sur les datasets avec présentation des résultats sous forme de dashboard et/ou possibilité d&rsquo;envoie d&rsquo;alertes.</p>
<p>Cela permet d&rsquo;éviter d&rsquo;avoir un arrêt de la chaîne de traitement mais cela induit qu&rsquo;il faut re-traiter toute la donnée corrompue.</p>
<p>Pour ce faire, il devient alors utile/indispensable de disposer du <strong>linéage de données</strong> (au minimum dataset).</p>
<p>Une fois l&rsquo;ensemble des datasets à re-produire en main, il faut alors en déduire les jobs qu&rsquo;il faut relancer et re-scheduler ces derniers (après une éventuelle correction) ou un sur-ensemble si le scheduler ne permet pas une exécution unitaire.</p>
<p>Si la <strong>qualité de données</strong> est effectuée de manière défensive (ie. qu&rsquo;un job ne s&rsquo;exécute que si ses pre/post conditions sont respectées) cela peut permettre :</p>
<ul>
<li>une consommation moindre de ressource de calcul (le dataset est lu et traité moins souvent)</li>
<li>d&rsquo;éviter d&rsquo;avoir à re-processer un ensemble de datasets corrompus</li>
</ul>
<p>Cependant, il se pose la question des données de qualité. En effet, il s&rsquo;agit souvent de données aggrégées (somme, moyenne, nombre d&rsquo;occurence, &hellip;). Il convient alors de les stocker et de les rendre accessibles aux jobs en ayant besoin afin d&rsquo;éviter de les recalculer.</p>
<p>Une autre question qui doit être posée est le couplage entre la génération de ces métriques de qualité et le traitement du job. Faut-il que le job produise ces données ou peut-on la voir comme une décoration du job?</p>
<h1 id="proposition">Proposition</h1>
<p>On a pu constater un certain nombre de points dans le paragraphe précédent (de manière totalement subjective et biaisé 😄).</p>
<h2 id="concepts">Concepts</h2>
<p>Dans cette partie, on va tenter de ré-assembler les morceaux au moins d&rsquo;un point de vue conceptuel&hellip;</p>
<p>Concernant le <strong>scheduler</strong>, on peut le voir de manière centrale. En effet, il a connaissance de nombreuses informations.</p>
<p>Pour la partie duplication d&rsquo;informations entre les jobs et leurs actions qui leur sont associées, si il était capable d&rsquo;introspecter le job, il serait presque possible de n&rsquo;avoir aucune information superflue à lui donner.</p>
<p>Si l&rsquo;ajout <em>magique</em> d&rsquo;une action n&rsquo;était pas souhaitable, il est tout à fait possible d&rsquo;imaginer un mécanisme de décorateur (au sens <em>design pattern</em>) qui permettrait d&rsquo;ajouter un comportement au job et qui irait l&rsquo;introspecter afin de découvrir la majorité des paramètres nécessaire à son fonctionnement.</p>
<p>Les informations dont le <strong>scheduler</strong> disposeraient alors permettrait de répondre :</p>
<ul>
<li>au <strong>linéage de données</strong> (du point de vue dataset)</li>
<li>au <strong>linéage de traitement</strong></li>
</ul>
<p>Concernant le <strong>catalogue de données</strong>, si il est vu découplé du metastore hive et si on considère que le schéma réel du dataset n&rsquo;est pas porté par le metastore hive mais par un autre format exhaustif (comme parquet, avro, protobuf), on obtient alors la notion de <strong>schema registry</strong>.</p>
<p>Ce <strong>schema registry</strong> deviendrait alors la source de vérité sur les datasets et chaque dataset alors consommé/produit devrait être connu de ce dernier et associé au format choisi (parquet, avro, protobuf) mais également à ses meta-données (localisation hive, etc). Le <strong>scheduler</strong> ou  le job devrait alors y accèder et il deviendrait alors possible de connaître les champs consommés et produits. En effet, si chaque input/output du job dispose de sa propre déclaration au niveau du <strong>schema registry</strong>, alors par construction, on connait les champs consommés/produits. Il devient alors possible de disposer du <strong>linéage de données avec la granularité champ</strong>.</p>
<p>Pour ce qui concerne les actions de type application d&rsquo;une politique de rétention ou altération du schema hive (dans le cas où un nouveau champ venait à être produit), il revient au <strong>schema registry</strong> d&rsquo;appliquer ces dernières. En effet, la politique de rétention peut être vu comme une metadonnée du dataset alors que l&rsquo;application d&rsquo;un changement de schéma au niveau hive n&rsquo;est qu&rsquo;une conséquence d&rsquo;un changement de schéma au niveau du <strong>schema regsitry</strong>. Ces opérations n&rsquo;ont pas à être portées par des pre/post actions du job mais c&rsquo;est bien de la responsabilité du <strong>schema registry</strong> dont il est question.</p>
<p>Enfin pour la <strong>qualité de données</strong>, si on considère que les pré/post condition ne sont que le résultat de la vérification d&rsquo;un contrat sur le dataset (ce dont il s&rsquo;agit réellement), alors cette information devrait être associée aux metadonnées du dataset et donc portée et exprimée au niveau du <strong>schema registry</strong>.</p>
<p>Cependant, puisqu&rsquo;il s&rsquo;agit de métadonnées, il est alors plus naturel d&rsquo;exprimer le contrat que doit respecter le dataset en mode descriptif et non via un mode impératif.</p>
<p>D&rsquo;un point de vue exécution, ce calcul de données aggrégées et la décision de savoir quel comportement adopté dans le cas où le contrat n&rsquo;est pas respecté pourrait être du ressort du <strong>scheduler</strong> en décorant le job au même titre qu&rsquo;il est décoré par les actions comme l&rsquo;ajout de partition hive.</p>
<p>Cependant, afin de s&rsquo;assurer que le contrat et la politique sont appliqués de manière cohérente, il convient alors de traduire le modèle descriptif en une liste d&rsquo;action à effectuer (comme la calcul de métrique, l&rsquo;arrêt de la chaine de traitement, etc.). Ainsi, cela permet de s&rsquo;assurer qu&rsquo;une même politique et qu&rsquo;un même contrat seront appliqués de manière homogène dans tout le <em>pipeline</em> de traitement.</p>
<p>Il peut également être envisagé de considérer les metriques aggrégés de qualités comme des metadonnées associées au dataset.</p>
<h2 id="détails-dimplémentation-à-prendre-en-considération">Détails d&rsquo;implémentation à prendre en considération</h2>
<p>Dans le cas d&rsquo;un <strong>scheduler</strong> qui serait multi-tenant et unique, l&rsquo;ensemble des informations dont il dispose est facilement disponible. Cependant si il est mono-tenant et/ou si il en existe plusieurs instances, alors ils doivent être interopérable et remonter leurs informations au sein d&rsquo;un service plus global qui aurait à sa charge l&rsquo;aggrégation et la mise à disposition des informations (dont le DAG global d&rsquo;exécution).</p>
<p>En outre, si le <strong>scheduler</strong> est multi-tenant, il doit prévoir la notion de <em>namespace</em> afin de gérer les problématiques de sécurité, de priorité, etc.</p>
<p>De même, il doit être capable d&rsquo;éviter les phénomènes de famine en disposant de <em>scheduler</em> permettant la préemption d&rsquo;exécution de jobs en prenant éventuellement en compte cette notion de <em>namespace</em>.</p>
<p>Concernant son design, il doit bien sûr être <em>scalable</em>, fournir les métriques nécessaires à son monitoring/supervision.</p>
<p>Il devrait également disposer d&rsquo;exécuteurs indépendants et autonomes pilotés par un <em>manager</em> afin de permettre la résilience des exécutions et et la bonne exécution des jobs/actions (en gérant les retry ou en tuant une action bloquée par exemple)</p>
<p>Concernant la mise en oeuvre de l&rsquo;introspection des jobs permettant au <strong>scheduler</strong>  de connaître les informations dont il a besoin afin de déterminer le graphe d&rsquo;exécution ainsi que les éventuels pre/post actions, elle pourrait être faite via un système de SPI (<em>Service Provider Interface</em>) couplé à un mini wrapper ou l&rsquo;ajout d&rsquo;annotation sur les opérations de lecture/écriture par exemple.</p>
<p>Concernant les informations de <strong>linéage de données et de traitement</strong> produite par le <strong>scheduler</strong>, elles pourraient être aggrégées et mise à disposition par un service tierce afin de permettre la séparation <em>of concerns</em>.</p>
<p>Pour connaitre le <strong>linéage de données avec la granularité champ</strong>, étant donné que l&rsquo;information est produite en scrutant les jobs qui accèdent au <strong>schema registry</strong>, cette remonté d&rsquo;accès aux datasets pourraient être faite à destination d&rsquo;un service tierce via un système de <em>hook</em>, <em>listener</em>. Ce service tierce (qui pourrait être le même service que celui utilisé pour le <strong>lineage de données et de traitement</strong>) serait alors en charge de leur aggrégation et de leur mise à disposition.</p>
<h2 id="exemple">Exemple</h2>
<p>Afin de tenter d&rsquo;illustrer de manière plus concrète tout ce long blabla, prenons un exemple.</p>
<p>Supposons qu&rsquo;on dispose d&rsquo;un dataset d1 à partir duquel est produit le dataset d2 via le job J écrit en SparkSql.</p>
<p>d1 dispose de 2 colonnes : d1_c1 et d1_c2 de type <code>int</code>.</p>
<p>d2 dispose de 1 colonne : d2_c1 (de type <code>int</code>) qui contient toutes les lignes de d1_c1 mais qui remplace toutes les valeurs négatives par 0</p>
<p><img src="https://blog.jetoile.fr/images/scheduler/schema01.png" alt="center"></p>
<p>Supposons que le <strong>schema registry</strong> utilise le format avro pour décrire les données et que le metastore de hive soit utilisé.</p>
<p>Supposons également qu&rsquo;on représente la qualité de données dans ce cas avec un pseudo langage type:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">d2.count(*) == d1.count(*)
d2.d2_c1 &gt;= 0
</code></pre></div><p>Dans ce cas, la déclaration dans le <strong>schema registry</strong> de d1 et d2 aurait pour conséquence la création de la database et des tables dans le metastore hive automatiquement.</p>
<p><img src="https://blog.jetoile.fr/images/scheduler/schema02.png" alt="center"></p>
<p>Concernant le job de traitement, on pourrait avoir dans sa version original :</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> spark <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">SparkSession</span>
  <span style="color:#f92672">.</span>builder<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>appName<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;job J in Scala&#34;</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>enableHiveSupport<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>getOrCreate<span style="color:#f92672">()</span>

<span style="color:#66d9ef">val</span> d1 <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>sql<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;SELECT d1_c1 FROM d1&#34;</span><span style="color:#f92672">)</span>

<span style="color:#66d9ef">val</span> d2 <span style="color:#66d9ef">=</span> df<span style="color:#f92672">.</span>withColumn<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">,</span> when<span style="color:#f92672">(</span>col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)</span> <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">)</span> otherwise col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)).</span>select<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">)</span>

d2<span style="color:#f92672">.</span>write<span style="color:#f92672">.</span>format<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;csv&#34;</span><span style="color:#f92672">).</span>save<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;hdfs://localhost:20112/test/d2&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>et dans sa version modifiée permettant l&rsquo;introspection par le <strong>scheduler</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> spark <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">SparkSession</span>
  <span style="color:#f92672">.</span>builder<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>appName<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;job J in Scala&#34;</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>enableHiveSupport<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>getOrCreate<span style="color:#f92672">()</span>

<span style="color:#66d9ef">val</span> d1 <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">ReaderWrapper</span><span style="color:#f92672">(</span>spark<span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;d1&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)</span>

<span style="color:#66d9ef">val</span> d2 <span style="color:#66d9ef">=</span> df<span style="color:#f92672">.</span>withColumn<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">,</span> when<span style="color:#f92672">(</span>col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)</span> <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">)</span> otherwise col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)).</span>select<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">)</span>

<span style="color:#a6e22e">WriterWrapper</span><span style="color:#f92672">(</span>spark<span style="color:#f92672">,</span> d2<span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;d2&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>A cette étape, on a donc :</p>
<ul>
<li>les datasets déclarés dans le <strong>schema registry</strong> ainsi que la définition du contrat de qualité</li>
<li>les databases et tables hive automatiquement créés dans le metastore hive</li>
</ul>
<p>Lors de l&rsquo;ajout du job J au sein du <strong>scheduler</strong>, ce dernier est alors capable de :</p>
<ul>
<li>introspecter le nouveau job J</li>
<li>en déduire les nouveaux noeuds d1 et d2 ainsi que le lien J qui les relie</li>
<li>reconstruire son DAG d&rsquo;exécution afin de prendre en compte cette nouvelle dépendance</li>
<li>déduire que pour exécuter J, il nécessite d&rsquo;avoir de la donnée pour le dataset d1 entrainant, par exemple, le positionnement d&rsquo;un <em>listener</em> au niveau du metastore hive afin de savoir si un changement se produit sur le dataset d1 (ajout d&rsquo;une partition par exemple)</li>
<li>grâce à l&rsquo;ajout du noeud d2, en déduire qu&rsquo;il doit aller requêter le <strong>schema registry</strong> pour y trouver éventuellement un nouveau contrat de qualité</li>
<li>traduire ce nouveau contrat:
<ul>
<li>en une pré-action à l&rsquo;éxécution du job J permettant de lancer un job de calcul du nombre de ligne sur d1</li>
<li>en une post-action à l&rsquo;éxécution du job J permettant de lancer un job de calcul du nombre de ligne sur d2 ainsi que de vérifier qu&rsquo;il n&rsquo;y a pas de valeurs négatives pour la colonne d2_c1</li>
</ul>
</li>
<li>une fois le job J exécuter, aller vérifier que les métriques aggrégées produites répondent bien aux attentes.</li>
</ul>
<p>Lors de l&rsquo;exécution du job J, l&rsquo;accès au <strong>schema registry</strong> permet de savoir que la colonne d1_c1 de d1 a été consommé afin de produire la colonne d2_c1 de d2 permettant ainsi de fournir l&rsquo;information au service s&rsquo;occupant d&rsquo;aggréger les informations pour fournir le <strong>lineage de données</strong>.</p>
<div class="note">
<p>A noter que lors de l&rsquo;instrospection du <strong>scheduler</strong> du job J, cette information de lineage pourrait également être déduite avant même l&rsquo;exécution du job J.</p>
</div>
<p>Concernant le <strong>lineage de traitement et de données d&rsquo;un point de vue dataset</strong>, il suffit simplement que le <strong>scheduler</strong> remonte l&rsquo;information au service de lineage.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Dans cet article, j&rsquo;ai essayé de poser un certain nombre de besoins qui sont généralement présents dans les projets Big Data ainsi que les constats que j&rsquo;ai pu faire et une proposition (qui vaut ce qu&rsquo;elle vaut&hellip;) pour ré-assembler ces différents points.</p>
<p>L&rsquo;approche que j&rsquo;ai aimé avec ma proposition est que, je trouve, qu&rsquo;au final, il y avait une certaine forme de cohérence un peu comme les pièces d&rsquo;un puzzle qu&rsquo;on emboite&hellip; avec en son centre le <strong>scheduler</strong> 😜</p>
<p>Bien sûr tous ces points sont discutables et c&rsquo;est d&rsquo;ailleurs la raison pour laquelle j&rsquo;ai posé mes réflexions dans cet article afin de fournir un matériel à partir duquel il sera possible de débattre/échanger/discuter si le coeur vous en dit 😉</p>
<p>Enfin, pour finir, je tenais à remercier Florent, DuyHai et Bruno pour leur relecture et leurs remarques pertinantes. 😙</p>

  
  <h4><i class="fas fa-share-alt" aria-hidden="true"></i>&nbsp;Share!</h4>
<ul class="share-buttons">
	<li><a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span class="sr-only">Share on Facebook</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://twitter.com/intent/tweet?source=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Tweet"><i class="fab fa-twitter" aria-hidden="true"></i><span class="sr-only">Tweet</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://plus.google.com/share?url=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Share on Google+"><i class="fab fa-google-plus" aria-hidden="true"></i><span class="sr-only">Share on Google+</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.tumblr.com/share?v=3&u=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Post to Tumblr"><i class="fab fa-tumblr" aria-hidden="true"></i><span class="sr-only">Post to Tumblr</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Pin it"><i class="fab fa-pinterest-p" aria-hidden="true"></i><span class="sr-only">Pin it</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.reddit.com/submit?url=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Submit to Reddit"><i class="fab fa-reddit-alien" aria-hidden="true"></i><span class="sr-only">Submit to Reddit</span></a>
	</li>
</ul>


<style>
	ul.share-buttons{
	  list-style: none;
	  padding: 0;
	}

	ul.share-buttons li{
	  display: inline;
	}

	ul.share-buttons .sr-only{
	  position: absolute;
	  clip: rect(1px 1px 1px 1px);
	  clip: rect(1px, 1px, 1px, 1px);
	  padding: 0;
	  border: 0;
	  height: 1px;
	  width: 1px;
	  overflow: hidden;
	}
</style>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://blog.jetoile.fr/2017/11/packaging-et-livraison-pour-hadoop-mode-demploi.html"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://blog.jetoile.fr/2017/11/packaging-et-livraison-pour-hadoop-mode-demploi.html">Packaging, test et livraison pour Hadoop : Mode d&#39;emploi</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://blog.jetoile.fr/2022/04/redcoat.html">Vis ma vie de redcoat</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://blog.jetoile.fr/2022/04/redcoat.html"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>


  
  
  
  
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'jetoile';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  

</div>

</div>
</div>
<script src="https://blog.jetoile.fr/js/ui.js"></script>
<script src="https://blog.jetoile.fr/js/menus.js"></script>




<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-11955429-1', 'auto');
    ga('send', 'pageview');
  }
</script>







</body>
</html>

