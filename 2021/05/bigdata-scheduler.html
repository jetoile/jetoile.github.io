<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.83.1" />

  <title>Big Data et Scheduler : Reflexion &middot; Jetoile</title>

    

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://blog.jetoile.fr/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://blog.jetoile.fr/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://blog.jetoile.fr/css/blackburn.css">

  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css">

  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel="stylesheet" type="text/css">

  
  <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/styles/androidstudio.min.css">
  <script async src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/highlight.min.js"></script>
  
  <script async src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://blog.jetoile.fr/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://blog.jetoile.fr/css/my.css">
    
  
  
    
        <script src="https://blog.jetoile.fr/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://blog.jetoile.fr/">Jetoile</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/post.html"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/about.html"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/contact.html"><i class='fa fa-phone fa-fw'></i>Contact</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://blog.jetoile.fr/hadoop-unit"><i class='fa fa-list fa-fw'></i>Hadoop Unit</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/jetoile" rel="me" target="_blank"><i class="fab fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/jetoile" rel="me" target="_blank"><i class="fab fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/khanh-tuong-maudoux-11b92b19" rel="me" target="_blank"><i class="fab fa-linkedin fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/jetoile" rel="me" target="_blank"><i class="fab fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small><a href='http://creativecommons.org/licenses/by/4.0/' rel='license'><img alt='Licence Creative Commons' src='https://blog.jetoile.fr/images/creative_common88x31.png' style='border-width:0'/></a></small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Big Data et Scheduler : Reflexion</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>18 May 2021</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://blog.jetoile.fr/tags/bigdata">bigdata</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://blog.jetoile.fr/tags/scheduler">scheduler</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://blog.jetoile.fr/tags/architecture">architecture</a>
    
  </div>
  
  

</div>

  <p><img src="https://blog.jetoile.fr/images/hadoop-all.png" alt="left-small">
Dans le monde Big Data, rapidement se pose un certain nombre de besoins.</p>
<p>Besoins qui, pris unitairement, sont d√©j√† complexes √† r√©soudre mais qui, mis bout √† bout, s&rsquo;av√®rent encore plus difficiles √† int√©grer.</p>
<p>Parmi ces besoins, on peut citer, par exemple, les besoins de qualit√© de donn√©es ou de lin√©age (probl√©matiques qui peuvent √™tre regrouper sous le terme de <em>data governance</em>).</p>
<p>Cet article n&rsquo;a pas pour objectif de fournir une solution cl√© en main ni de parler d&rsquo;outils d√©j√† existant mais plut√¥t de poser diff√©rentes r√©flexions que j&rsquo;ai pu avoir afin de savoir si elles avaient un sens&hellip;</p>
<!-- more -->
<h1 id="besoins">Besoins</h1>
<p>Lorsque l&rsquo;on est confront√© au Big Data, les besoins qui en d√©coulent sont les suivants :</p>
<ul>
<li>avoir un <strong>scheduler</strong> scalable permettant d&rsquo;ex√©cuter et ordonnancer les diff√©rents jobs (qu&rsquo;ils soient MapReduce, Spark, Hive ou autres) mais √©galement ex√©cuter des actions qui leurs sont associ√©es (d√©placement de fichiers/r√©pertoires, cr√©ation/suppression/modification de tables hive, cr√©ation de fichiers _SUCCESS, appliquer une politique de r√©tention, etc.)</li>
<li>avoir un <strong>catalogue de donn√©es</strong> (afin de conna√Ætre ses datasets) pour pouvoir retrouver l&rsquo;information</li>
<li>disposer d&rsquo;un <strong>lineage de donn√©es</strong> (afin de pouvoir savoir √† partir de quel dataset est issu tel autre)</li>
<li>avoir de la <strong>qualit√© de donn√©es</strong></li>
</ul>
<div class="note">
<p>A noter que quand il est fait mention de <strong>scheduler</strong>, il ne s&rsquo;agit pas de cluster manager comme Yarn, Mesos ou k8s mais d&rsquo;un orchestrateur de t√¢ches comme Oozie ou Airflow (pour ne citer qu&rsquo;eux).</p>
</div>
<p>Si nous revenons plus pr√©cis√©ment sur certains de ces points, <strong>le lineage de donn√©es</strong> et la <strong>qualit√© de donn√©es</strong> m√©ritent qu&rsquo;on s&rsquo;y arr√™te un peu plus longtemps.</p>
<p>Concernant le <strong>lineage de donn√©es</strong>, cela est int√©ressant de savoir √† partir de quel dataset un dataset est issu mais il peut √©galement √™tre utile de disposer d&rsquo;un <strong>lineage de traitement</strong>, c&rsquo;est-√†-dire savoir quel job a produit quel dataset. En effet, cela permet de facilement savoir, si un dataset a, par exemple, mal √©t√© produit, quel est le job dans la cha√Æne qui est fautif.</p>
<p>De m√™me, dans un contexte de v√©racit√© ou d&rsquo;audit, pouvoir prouver que tel traitement produit bien le r√©sultat voulu peut √™tre primordial.</p>
<p>En outre, en plus d&rsquo;avoir un <strong>lineage de donn√©es</strong> portant sur le dataset, il peut √™tre int√©ressant d&rsquo;avoir un lineage de donn√©es portant sur le contenu du dataset. En effet, conna√Ætre la propagation d&rsquo;une information (ou d&rsquo;un champ) de mani√®re plus fine peut √™tre n√©cessaire.</p>
<p>Pour ce qui concerne la <strong>qualit√© de donn√©es</strong>, cela l√®ve diff√©rentes interrogations :</p>
<ul>
<li>que faire lorsque la donn√©e produite ne respecte pas le contrat (car oui, il s&rsquo;agit bien d&rsquo;un contrat au sens pr√©-condition/post-condition) :
<ul>
<li>doit-on arr√™ter la cha√Æne de traitement?</li>
<li>doit-on lever une alerte et continuer le traitement? et si oui, que faire de la donn√©e ignor√©e/mal produite (doit-on faire une <em>dead letter queue</em> sur la donn√©e en amont ou en aval?, quelle est la politique de traitement de cette <em>dead letter queue</em>?, etc&hellip;)?</li>
</ul>
</li>
<li>doit-on √™tre pro-actif (ie. faire une v√©rification avant/apr√®s l&rsquo;ex√©cution de la transformation) ou le faire de mani√®re lazy/asynchrone?</li>
<li>comment doit √™tre exprim√© le contrat et qui (au sens traitement) doit v√©rifier la v√©racit√© de ce dernier?</li>
<li>si une m√™me op√©ration doit √™tre appliqu√©e sur diff√©rents datasets √† diff√©rentes √©tapes du <em>pipeline</em> de traitement, comment s&rsquo;assurer qu&rsquo;elle soit consistante (ie. ex√©cuter de la m√™me mani√®re) et cela malgr√© l&rsquo;utilisation de diff√©rentes technologies?</li>
</ul>
<div class="note">
<p>A noter que lorsqu&rsquo;il est fait mention de <strong>qualit√© de donn√©es</strong>, il s&rsquo;agit surtout de v√©rifier la consistance de la donn√©e sur un p√©rim√®tre restreint et simple.</p>
<p>En effet, y int√©grer des v√©rifications plus larges tels que des r√®gles m√©tiers, un croisement de diff√©rents datasets ou m√™me  d&rsquo;y appliquer un mod√®le issu de <em>machine learning</em> sort du p√©rim√®tre de cet article et s&rsquo;av√®re difficile √† exprimer.</p>
<p>En outre, de tels traitements sont g√©n√©ralements r√©alis√©s √† posteriori.</p>
</div>
<p>Bref, plus de questions que de r√©ponses&hellip; mais qu&rsquo;il est important de se poser.</p>
<p>Aussi, le besoin peut maintenant √™tre exprim√© de la mani√®re suivante :</p>
<ul>
<li>avoir un <strong>scheduler</strong></li>
<li>avoir un <strong>catalogue de donn√©es</strong></li>
<li>disposer d&rsquo;un <strong>lineage de donn√©es</strong> au niveau du dataset</li>
<li>disposer d&rsquo;un <strong>lineage de donn√©es</strong> au niveau du champ</li>
<li>disposer d&rsquo;un <strong>lineage de traitement</strong></li>
<li>avoir de la <strong>qualit√© de donn√©es</strong> :
<ul>
<li>disposer d&rsquo;un moyen pour exprimer le contrat √† respecter</li>
<li>disposer d&rsquo;un moyen pour exprimer le comportement √† avoir si le contrat n&rsquo;est pas respect√©</li>
</ul>
</li>
</ul>
<h1 id="constat">Constat</h1>
<h2 id="scheduler">Scheduler</h2>
<p>Si on revient sur la partie <strong>scheduler</strong>, un constat peut √™tre fait concernant les solutions les plus souvent utilis√©es/connues (airflow ou oozie pour n&rsquo;en citer que quelques-unes) : elles sont verbeuses (au sens <em>don&rsquo;t repeat yourself</em>).</p>
<p>Afin de permettre √† l&rsquo;orchestrateur de calculer/repr√©senter son <em>DAG</em> (Directed Acyclic Graph) d&rsquo;ex√©cution, il faut :</p>
<ul>
<li>indiquer/repr√©senter les input et output des jobs</li>
<li>ajouter les pre/post actions √† ex√©cuter (√† noter que la v√©rification des conditions de l&rsquo;ex√©cution d&rsquo;un job peut √™tre vu comme un pr√©-action)</li>
</ul>
<p>Pourtant, devoir indiquer/repr√©senter les input/output d&rsquo;un job est d√©j√† exprim√© dans le job en lui-m√™me (par exemple, si on prend un job Spark, afin de pouvoir consommer/produire un RDD/DataSet/DataFrame, il faut effectuer une op√©ration de lecture/√©criture explicite. De m√™me pour une requ√™te SQL o√π ces informations apparaissent).</p>
<p>Concernant les pre/post actions, une grande majorit√© d&rsquo;entre elles peuvent √™tre d√©duite du job : par exemple, on ne peut lire une donn√©e non pr√©sente. Ainsi devoir l&rsquo;exprimer au niveau du <strong>scheduler</strong> est redondant.</p>
<p>De m√™me si on <em>sait</em> que le job <em>doit</em> cr√©er/ajouter la partition hive pour la donn√©e produite, devoir le re-pr√©ciser pour chaque job au niveau du scheduler est dommageable.</p>
<p>Si un alter table hive (dans le cas o√π un nouveau champ venait √† √™tre produit) ou une politique de r√©tention doivent √™tre effectu√©s, nous y reviendrons un peu plus tard&hellip; üòú</p>
<p>Bref, on peut donc constater que la majorit√© des choses qui doivent √™tre exprim√©es dans le scheduler sont redondantes.</p>
<h2 id="catalogue-de-donn√©es">Catalogue de donn√©es</h2>
<p>Le catalogue de donn√©es permet de conna√Ætre l&rsquo;ensemble des datasets du syst√®me. Afin de le peupler, plusieurs approches sont possibles :</p>
<ul>
<li>utiliser directement le metastore hive comme √©tant le catalogue de donn√©es</li>
<li>dissocier le catalogue de donn√©es du m√©tastore hive</li>
</ul>
<p>Dissocier le catalogue de donn√©es du m√©tastore hive apporte plusieurs avantages :</p>
<ul>
<li>le d√©couplage</li>
<li>la possibilit√© d&rsquo;ajouter d&rsquo;autres types d&rsquo;informations plus m√©ta que ce qui est permis via le metastore (documentation, &hellip;)</li>
</ul>
<p>Cependant, cela demande √† avoir √† le maintenir/synchroniser et, pour cela, plusieurs approches sont possibles :</p>
<ul>
<li>une approche <em>lazy</em> c&rsquo;est √† dire un m√©canisme allant scruter le metastore hive (que cela soit fait en positionnant un <em>listener</em> directement sur ce dernier ou via un job allant l&rsquo;interroger)</li>
<li>une approche plus <em>invasive</em> qui consiste √† coupler fortement les jobs en leur demandant d&rsquo;aller renseigner le catalogue de donn√©es</li>
<li>une approche <em>entre deux</em> qui consiste √† s&rsquo;appuyer sur l&rsquo;observabilit√© des jobs</li>
</ul>
<p>En outre, vient se poser la question de la <em>v√©racit√©</em> du m√©tastore hive. En effet, le metastore hive est une projection du dataset qui peut √™tre incompl√®te puisqu&rsquo;on est en fonctionnement <em>schema on read</em>. Le dataset r√©el peut donc √™tre plus complet que ce qui est d√©clar√© dans le metastore (le cas des <em>view</em> n&rsquo;est, ici, pas pris en compte) (√† noter que l&rsquo;utilisation de SparkSQL permet de r√©duire la chance de diverger).</p>
<h2 id="lin√©age-de-donn√©es">Lin√©age de donn√©es</h2>
<p>Le <strong>lineage de donn√©es</strong> est une probl√©matique non triviale et est parfois faite de mani√®re d√©clarative (et donc non √† jour&hellip;).</p>
<p>Cependant, les jobs disposent de l&rsquo;information et il est donc possible de r√©-aggr√©ger cette derni√®re de mani√®re pro-active ou non afin de disposer d&rsquo;un lin√©age (au moins le lineage de dataset).</p>
<p>Bien s√ªr disposer de nombreuses technologies de traitement rend cela plus complexe.</p>
<p>Une autre approche pourrait consister √† corr√©ler les acc√®s au metastore hive et le plan d&rsquo;ex√©cution des jobs mais il se pose alors la m√™me question de la compl√©tude de l&rsquo;information que pour le <strong>catalogue de donn√©es</strong>.</p>
<p>Concernant le lin√©age de donn√©es au niveau champ, cela s&rsquo;av√®re assez compliqu√©.</p>
<h2 id="lin√©age-de-traitement">Lin√©age de traitement</h2>
<p>Disposer d&rsquo;un <strong>lin√©age de traitement</strong> complet (ie. pas seulement avec une vision d&rsquo;un <em>workflow</em> donn√©) peut s&rsquo;av√©rer complexe avec les scheduler actuels.</p>
<p>En outre, si plusieurs technologies de scheduler sont utilis√©es ou si il en existe plusieurs instances, le manque d&rsquo;API/interface commune rend l&rsquo;extraction et la corr√©lation difficile.</p>
<h2 id="qualit√©-de-donn√©es">Qualit√© de donn√©es</h2>
<p>La <strong>qualit√© de donn√©es</strong> est souvent effectu√©e a posteriori sur les datasets avec pr√©sentation des r√©sultats sous forme de dashboard et/ou possibilit√© d&rsquo;envoie d&rsquo;alertes.</p>
<p>Cela permet d&rsquo;√©viter d&rsquo;avoir un arr√™t de la cha√Æne de traitement mais cela induit qu&rsquo;il faut re-traiter toute la donn√©e corrompue.</p>
<p>Pour ce faire, il devient alors utile/indispensable de disposer du <strong>lin√©age de donn√©es</strong> (au minimum dataset).</p>
<p>Une fois l&rsquo;ensemble des datasets √† re-produire en main, il faut alors en d√©duire les jobs qu&rsquo;il faut relancer et re-scheduler ces derniers (apr√®s une √©ventuelle correction) ou un sur-ensemble si le scheduler ne permet pas une ex√©cution unitaire.</p>
<p>Si la <strong>qualit√© de donn√©es</strong> est effectu√©e de mani√®re d√©fensive (ie. qu&rsquo;un job ne s&rsquo;ex√©cute que si ses pre/post conditions sont respect√©es) cela peut permettre :</p>
<ul>
<li>une consommation moindre de ressource de calcul (le dataset est lu et trait√© moins souvent)</li>
<li>d&rsquo;√©viter d&rsquo;avoir √† re-processer un ensemble de datasets corrompus</li>
</ul>
<p>Cependant, il se pose la question des donn√©es de qualit√©. En effet, il s&rsquo;agit souvent de donn√©es aggr√©g√©es (somme, moyenne, nombre d&rsquo;occurence, &hellip;). Il convient alors de les stocker et de les rendre accessibles aux jobs en ayant besoin afin d&rsquo;√©viter de les recalculer.</p>
<p>Une autre question qui doit √™tre pos√©e est le couplage entre la g√©n√©ration de ces m√©triques de qualit√© et le traitement du job. Faut-il que le job produise ces donn√©es ou peut-on la voir comme une d√©coration du job?</p>
<h1 id="proposition">Proposition</h1>
<p>On a pu constater un certain nombre de points dans le paragraphe pr√©c√©dent (de mani√®re totalement subjective et biais√© üòÑ).</p>
<h2 id="concepts">Concepts</h2>
<p>Dans cette partie, on va tenter de r√©-assembler les morceaux au moins d&rsquo;un point de vue conceptuel&hellip;</p>
<p>Concernant le <strong>scheduler</strong>, on peut le voir de mani√®re centrale. En effet, il a connaissance de nombreuses informations.</p>
<p>Pour la partie duplication d&rsquo;informations entre les jobs et leurs actions qui leur sont associ√©es, si il √©tait capable d&rsquo;introspecter le job, il serait presque possible de n&rsquo;avoir aucune information superflue √† lui donner.</p>
<p>Si l&rsquo;ajout <em>magique</em> d&rsquo;une action n&rsquo;√©tait pas souhaitable, il est tout √† fait possible d&rsquo;imaginer un m√©canisme de d√©corateur (au sens <em>design pattern</em>) qui permettrait d&rsquo;ajouter un comportement au job et qui irait l&rsquo;introspecter afin de d√©couvrir la majorit√© des param√®tres n√©cessaire √† son fonctionnement.</p>
<p>Les informations dont le <strong>scheduler</strong> disposeraient alors permettrait de r√©pondre :</p>
<ul>
<li>au <strong>lin√©age de donn√©es</strong> (du point de vue dataset)</li>
<li>au <strong>lin√©age de traitement</strong></li>
</ul>
<p>Concernant le <strong>catalogue de donn√©es</strong>, si il est vu d√©coupl√© du metastore hive et si on consid√®re que le sch√©ma r√©el du dataset n&rsquo;est pas port√© par le metastore hive mais par un autre format exhaustif (comme parquet, avro, protobuf), on obtient alors la notion de <strong>schema registry</strong>.</p>
<p>Ce <strong>schema registry</strong> deviendrait alors la source de v√©rit√© sur les datasets et chaque dataset alors consomm√©/produit devrait √™tre connu de ce dernier et associ√© au format choisi (parquet, avro, protobuf) mais √©galement √† ses meta-donn√©es (localisation hive, etc). Le <strong>scheduler</strong> ou  le job devrait alors y acc√®der et il deviendrait alors possible de conna√Ætre les champs consomm√©s et produits. En effet, si chaque input/output du job dispose de sa propre d√©claration au niveau du <strong>schema registry</strong>, alors par construction, on connait les champs consomm√©s/produits. Il devient alors possible de disposer du <strong>lin√©age de donn√©es avec la granularit√© champ</strong>.</p>
<p>Pour ce qui concerne les actions de type application d&rsquo;une politique de r√©tention ou alt√©ration du schema hive (dans le cas o√π un nouveau champ venait √† √™tre produit), il revient au <strong>schema registry</strong> d&rsquo;appliquer ces derni√®res. En effet, la politique de r√©tention peut √™tre vu comme une metadonn√©e du dataset alors que l&rsquo;application d&rsquo;un changement de sch√©ma au niveau hive n&rsquo;est qu&rsquo;une cons√©quence d&rsquo;un changement de sch√©ma au niveau du <strong>schema regsitry</strong>. Ces op√©rations n&rsquo;ont pas √† √™tre port√©es par des pre/post actions du job mais c&rsquo;est bien de la responsabilit√© du <strong>schema registry</strong> dont il est question.</p>
<p>Enfin pour la <strong>qualit√© de donn√©es</strong>, si on consid√®re que les pr√©/post condition ne sont que le r√©sultat de la v√©rification d&rsquo;un contrat sur le dataset (ce dont il s&rsquo;agit r√©ellement), alors cette information devrait √™tre associ√©e aux metadonn√©es du dataset et donc port√©e et exprim√©e au niveau du <strong>schema registry</strong>.</p>
<p>Cependant, puisqu&rsquo;il s&rsquo;agit de m√©tadonn√©es, il est alors plus naturel d&rsquo;exprimer le contrat que doit respecter le dataset en mode descriptif et non via un mode imp√©ratif.</p>
<p>D&rsquo;un point de vue ex√©cution, ce calcul de donn√©es aggr√©g√©es et la d√©cision de savoir quel comportement adopt√© dans le cas o√π le contrat n&rsquo;est pas respect√© pourrait √™tre du ressort du <strong>scheduler</strong> en d√©corant le job au m√™me titre qu&rsquo;il est d√©cor√© par les actions comme l&rsquo;ajout de partition hive.</p>
<p>Cependant, afin de s&rsquo;assurer que le contrat et la politique sont appliqu√©s de mani√®re coh√©rente, il convient alors de traduire le mod√®le descriptif en une liste d&rsquo;action √† effectuer (comme la calcul de m√©trique, l&rsquo;arr√™t de la chaine de traitement, etc.). Ainsi, cela permet de s&rsquo;assurer qu&rsquo;une m√™me politique et qu&rsquo;un m√™me contrat seront appliqu√©s de mani√®re homog√®ne dans tout le <em>pipeline</em> de traitement.</p>
<p>Il peut √©galement √™tre envisag√© de consid√©rer les metriques aggr√©g√©s de qualit√©s comme des metadonn√©es associ√©es au dataset.</p>
<h2 id="d√©tails-dimpl√©mentation-√†-prendre-en-consid√©ration">D√©tails d&rsquo;impl√©mentation √† prendre en consid√©ration</h2>
<p>Dans le cas d&rsquo;un <strong>scheduler</strong> qui serait multi-tenant et unique, l&rsquo;ensemble des informations dont il dispose est facilement disponible. Cependant si il est mono-tenant et/ou si il en existe plusieurs instances, alors ils doivent √™tre interop√©rable et remonter leurs informations au sein d&rsquo;un service plus global qui aurait √† sa charge l&rsquo;aggr√©gation et la mise √† disposition des informations (dont le DAG global d&rsquo;ex√©cution).</p>
<p>En outre, si le <strong>scheduler</strong> est multi-tenant, il doit pr√©voir la notion de <em>namespace</em> afin de g√©rer les probl√©matiques de s√©curit√©, de priorit√©, etc.</p>
<p>De m√™me, il doit √™tre capable d&rsquo;√©viter les ph√©nom√®nes de famine en disposant de <em>scheduler</em> permettant la pr√©emption d&rsquo;ex√©cution de jobs en prenant √©ventuellement en compte cette notion de <em>namespace</em>.</p>
<p>Concernant son design, il doit bien s√ªr √™tre <em>scalable</em>, fournir les m√©triques n√©cessaires √† son monitoring/supervision.</p>
<p>Il devrait √©galement disposer d&rsquo;ex√©cuteurs ind√©pendants et autonomes pilot√©s par un <em>manager</em> afin de permettre la r√©silience des ex√©cutions et et la bonne ex√©cution des jobs/actions (en g√©rant les retry ou en tuant une action bloqu√©e par exemple)</p>
<p>Concernant la mise en oeuvre de l&rsquo;introspection des jobs permettant au <strong>scheduler</strong>  de conna√Ætre les informations dont il a besoin afin de d√©terminer le graphe d&rsquo;ex√©cution ainsi que les √©ventuels pre/post actions, elle pourrait √™tre faite via un syst√®me de SPI (<em>Service Provider Interface</em>) coupl√© √† un mini wrapper ou l&rsquo;ajout d&rsquo;annotation sur les op√©rations de lecture/√©criture par exemple.</p>
<p>Concernant les informations de <strong>lin√©age de donn√©es et de traitement</strong> produite par le <strong>scheduler</strong>, elles pourraient √™tre aggr√©g√©es et mise √† disposition par un service tierce afin de permettre la s√©paration <em>of concerns</em>.</p>
<p>Pour connaitre le <strong>lin√©age de donn√©es avec la granularit√© champ</strong>, √©tant donn√© que l&rsquo;information est produite en scrutant les jobs qui acc√®dent au <strong>schema registry</strong>, cette remont√© d&rsquo;acc√®s aux datasets pourraient √™tre faite √† destination d&rsquo;un service tierce via un syst√®me de <em>hook</em>, <em>listener</em>. Ce service tierce (qui pourrait √™tre le m√™me service que celui utilis√© pour le <strong>lineage de donn√©es et de traitement</strong>) serait alors en charge de leur aggr√©gation et de leur mise √† disposition.</p>
<h2 id="exemple">Exemple</h2>
<p>Afin de tenter d&rsquo;illustrer de mani√®re plus concr√®te tout ce long blabla, prenons un exemple.</p>
<p>Supposons qu&rsquo;on dispose d&rsquo;un dataset d1 √† partir duquel est produit le dataset d2 via le job J √©crit en SparkSql.</p>
<p>d1 dispose de 2 colonnes : d1_c1 et d1_c2 de type <code>int</code>.</p>
<p>d2 dispose de 1 colonne : d2_c1 (de type <code>int</code>) qui contient toutes les lignes de d1_c1 mais qui remplace toutes les valeurs n√©gatives par 0</p>
<p><img src="https://blog.jetoile.fr/images/scheduler/schema01.png" alt="center"></p>
<p>Supposons que le <strong>schema registry</strong> utilise le format avro pour d√©crire les donn√©es et que le metastore de hive soit utilis√©.</p>
<p>Supposons √©galement qu&rsquo;on repr√©sente la qualit√© de donn√©es dans ce cas avec un pseudo langage type:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-text" data-lang="text">d2.count(*) == d1.count(*)
d2.d2_c1 &gt;= 0
</code></pre></div><p>Dans ce cas, la d√©claration dans le <strong>schema registry</strong> de d1 et d2 aurait pour cons√©quence la cr√©ation de la database et des tables dans le metastore hive automatiquement.</p>
<p><img src="https://blog.jetoile.fr/images/scheduler/schema02.png" alt="center"></p>
<p>Concernant le job de traitement, on pourrait avoir dans sa version original :</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> spark <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">SparkSession</span>
  <span style="color:#f92672">.</span>builder<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>appName<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;job J in Scala&#34;</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>enableHiveSupport<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>getOrCreate<span style="color:#f92672">()</span>

<span style="color:#66d9ef">val</span> d1 <span style="color:#66d9ef">=</span> spark<span style="color:#f92672">.</span>sql<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;SELECT d1_c1 FROM d1&#34;</span><span style="color:#f92672">)</span>

<span style="color:#66d9ef">val</span> d2 <span style="color:#66d9ef">=</span> df<span style="color:#f92672">.</span>withColumn<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">,</span> when<span style="color:#f92672">(</span>col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)</span> <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">)</span> otherwise col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)).</span>select<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">)</span>

d2<span style="color:#f92672">.</span>write<span style="color:#f92672">.</span>format<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;csv&#34;</span><span style="color:#f92672">).</span>save<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;hdfs://localhost:20112/test/d2&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>et dans sa version modifi√©e permettant l&rsquo;introspection par le <strong>scheduler</strong></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-scala" data-lang="scala"><span style="color:#66d9ef">val</span> spark <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">SparkSession</span>
  <span style="color:#f92672">.</span>builder<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>appName<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;job J in Scala&#34;</span><span style="color:#f92672">)</span>
  <span style="color:#f92672">.</span>enableHiveSupport<span style="color:#f92672">()</span>
  <span style="color:#f92672">.</span>getOrCreate<span style="color:#f92672">()</span>

<span style="color:#66d9ef">val</span> d1 <span style="color:#66d9ef">=</span> <span style="color:#a6e22e">ReaderWrapper</span><span style="color:#f92672">(</span>spark<span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;d1&#34;</span><span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)</span>

<span style="color:#66d9ef">val</span> d2 <span style="color:#66d9ef">=</span> df<span style="color:#f92672">.</span>withColumn<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">,</span> when<span style="color:#f92672">(</span>col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)</span> <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">,</span> <span style="color:#ae81ff">0</span><span style="color:#f92672">)</span> otherwise col<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d1_c1&#34;</span><span style="color:#f92672">)).</span>select<span style="color:#f92672">(</span><span style="color:#e6db74">&#34;d2_c1&#34;</span><span style="color:#f92672">)</span>

<span style="color:#a6e22e">WriterWrapper</span><span style="color:#f92672">(</span>spark<span style="color:#f92672">,</span> d2<span style="color:#f92672">,</span> <span style="color:#e6db74">&#34;d2&#34;</span><span style="color:#f92672">)</span>
</code></pre></div><p>A cette √©tape, on a donc :</p>
<ul>
<li>les datasets d√©clar√©s dans le <strong>schema registry</strong> ainsi que la d√©finition du contrat de qualit√©</li>
<li>les databases et tables hive automatiquement cr√©√©s dans le metastore hive</li>
</ul>
<p>Lors de l&rsquo;ajout du job J au sein du <strong>scheduler</strong>, ce dernier est alors capable de :</p>
<ul>
<li>introspecter le nouveau job J</li>
<li>en d√©duire les nouveaux noeuds d1 et d2 ainsi que le lien J qui les relie</li>
<li>reconstruire son DAG d&rsquo;ex√©cution afin de prendre en compte cette nouvelle d√©pendance</li>
<li>d√©duire que pour ex√©cuter J, il n√©cessite d&rsquo;avoir de la donn√©e pour le dataset d1 entrainant, par exemple, le positionnement d&rsquo;un <em>listener</em> au niveau du metastore hive afin de savoir si un changement se produit sur le dataset d1 (ajout d&rsquo;une partition par exemple)</li>
<li>gr√¢ce √† l&rsquo;ajout du noeud d2, en d√©duire qu&rsquo;il doit aller requ√™ter le <strong>schema registry</strong> pour y trouver √©ventuellement un nouveau contrat de qualit√©</li>
<li>traduire ce nouveau contrat:
<ul>
<li>en une pr√©-action √† l&rsquo;√©x√©cution du job J permettant de lancer un job de calcul du nombre de ligne sur d1</li>
<li>en une post-action √† l&rsquo;√©x√©cution du job J permettant de lancer un job de calcul du nombre de ligne sur d2 ainsi que de v√©rifier qu&rsquo;il n&rsquo;y a pas de valeurs n√©gatives pour la colonne d2_c1</li>
</ul>
</li>
<li>une fois le job J ex√©cuter, aller v√©rifier que les m√©triques aggr√©g√©es produites r√©pondent bien aux attentes.</li>
</ul>
<p>Lors de l&rsquo;ex√©cution du job J, l&rsquo;acc√®s au <strong>schema registry</strong> permet de savoir que la colonne d1_c1 de d1 a √©t√© consomm√© afin de produire la colonne d2_c1 de d2 permettant ainsi de fournir l&rsquo;information au service s&rsquo;occupant d&rsquo;aggr√©ger les informations pour fournir le <strong>lineage de donn√©es</strong>.</p>
<div class="note">
<p>A noter que lors de l&rsquo;instrospection du <strong>scheduler</strong> du job J, cette information de lineage pourrait √©galement √™tre d√©duite avant m√™me l&rsquo;ex√©cution du job J.</p>
</div>
<p>Concernant le <strong>lineage de traitement et de donn√©es d&rsquo;un point de vue dataset</strong>, il suffit simplement que le <strong>scheduler</strong> remonte l&rsquo;information au service de lineage.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Dans cet article, j&rsquo;ai essay√© de poser un certain nombre de besoins qui sont g√©n√©ralement pr√©sents dans les projets Big Data ainsi que les constats que j&rsquo;ai pu faire et une proposition (qui vaut ce qu&rsquo;elle vaut&hellip;) pour r√©-assembler ces diff√©rents points.</p>
<p>L&rsquo;approche que j&rsquo;ai aim√© avec ma proposition est que, je trouve, qu&rsquo;au final, il y avait une certaine forme de coh√©rence un peu comme les pi√®ces d&rsquo;un puzzle qu&rsquo;on emboite&hellip; avec en son centre le <strong>scheduler</strong> üòú</p>
<p>Bien s√ªr tous ces points sont discutables et c&rsquo;est d&rsquo;ailleurs la raison pour laquelle j&rsquo;ai pos√© mes r√©flexions dans cet article afin de fournir un mat√©riel √† partir duquel il sera possible de d√©battre/√©changer/discuter si le coeur vous en dit üòâ</p>
<p>Enfin, pour finir, je tenais √† remercier Florent, DuyHai et Bruno pour leur relecture et leurs remarques pertinantes. üòô</p>

  
  <h4><i class="fas fa-share-alt" aria-hidden="true"></i>&nbsp;Share!</h4>
<ul class="share-buttons">
	<li><a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span class="sr-only">Share on Facebook</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://twitter.com/intent/tweet?source=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Tweet"><i class="fab fa-twitter" aria-hidden="true"></i><span class="sr-only">Tweet</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="https://plus.google.com/share?url=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Share on Google+"><i class="fab fa-google-plus" aria-hidden="true"></i><span class="sr-only">Share on Google+</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.tumblr.com/share?v=3&u=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Post to Tumblr"><i class="fab fa-tumblr" aria-hidden="true"></i><span class="sr-only">Post to Tumblr</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Pin it"><i class="fab fa-pinterest-p" aria-hidden="true"></i><span class="sr-only">Pin it</span></a>
	</li>&nbsp;&nbsp;&nbsp;
	<li><a href="http://www.reddit.com/submit?url=https%3a%2f%2fblog.jetoile.fr%2f2021%2f05%2fbigdata-scheduler.html" target="_blank" title="Submit to Reddit"><i class="fab fa-reddit-alien" aria-hidden="true"></i><span class="sr-only">Submit to Reddit</span></a>
	</li>
</ul>


<style>
	ul.share-buttons{
	  list-style: none;
	  padding: 0;
	}

	ul.share-buttons li{
	  display: inline;
	}

	ul.share-buttons .sr-only{
	  position: absolute;
	  clip: rect(1px 1px 1px 1px);
	  clip: rect(1px, 1px, 1px, 1px);
	  padding: 0;
	  border: 0;
	  height: 1px;
	  width: 1px;
	  overflow: hidden;
	}
</style>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://blog.jetoile.fr/2017/11/packaging-et-livraison-pour-hadoop-mode-demploi.html"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://blog.jetoile.fr/2017/11/packaging-et-livraison-pour-hadoop-mode-demploi.html">Packaging, test et livraison pour Hadoop : Mode d&#39;emploi</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://blog.jetoile.fr/2022/04/redcoat.html">Vis ma vie de redcoat</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://blog.jetoile.fr/2022/04/redcoat.html"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>


  
  
  
  
<div id="disqus_thread"></div>
<script type="text/javascript">

(function() {
    
    
    if (window.location.hostname == "localhost")
        return;

    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    var disqus_shortname = 'jetoile';
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


  

</div>

</div>
</div>
<script src="https://blog.jetoile.fr/js/ui.js"></script>
<script src="https://blog.jetoile.fr/js/menus.js"></script>




<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-11955429-1', 'auto');
    ga('send', 'pageview');
  }
</script>







</body>
</html>

